{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoogleQA.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acmilannesta/Bert-embedding/blob/master/GoogleQA_tfhub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D82bieSpLcuc",
        "colab_type": "code",
        "outputId": "38f0ca90-f050-4ff5-fe26-2b5af88049d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Dec 18 00:18:05 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JErzYVOxLtWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu --upgrade\n",
        "\n",
        "# bert uncased base\n",
        "!wget https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1?tf-hub-format=compressed -O bbu\n",
        "!mkdir bert_base_uncased\n",
        "!tar -xzf bbu -C bert_base_uncased\n",
        "\n",
        "# bert cased base\n",
        "!wget https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1?tf-hub-format=compressed -O bbc\n",
        "!mkdir bert_base_cased\n",
        "!tar -xzf bbc -C bert_base_cased\n",
        "\n",
        "# albert base\n",
        "!wget https://tfhub.dev/google/albert_base/1?tf-hub-format=compressed -O ab\n",
        "!mkdir albert_base\n",
        "!tar -xzf ab -C albert_base\n",
        "\n",
        "# bert uncased large\n",
        "!wget https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1?tf-hub-format=compressed -O blu\n",
        "!mkdir bert_large_uncased\n",
        "!tar -xzf blu -C bert_large_uncased"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBrwK8dwLyw8",
        "colab_type": "code",
        "outputId": "ebe3faaa-cc33-4ac3-fa18-0c9e124bb01d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaDm4NWvLp_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1, '/content/drive/My Drive/GoogleQA')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, gc\n",
        "import codecs\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.backend import set_session\n",
        "# from keras.callbacks import Callback\n",
        "# from keras.models import Model, load_model\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GroupKFold, KFold, RepeatedKFold\n",
        "from scipy.stats import spearmanr\n",
        "from tqdm import tqdm\n",
        "import tensorflow_hub as hub\n",
        "# from albert_tokenization import FullTokenizer\n",
        "from tokenizer import Tokenizer\n",
        "from warmup_v2 import AdamWarmup, calc_train_steps\n",
        "tf.get_logger().setLevel('ERROR') \n",
        "# from keras_bert import load_trained_model_from_checkpoint, Tokenizer, AdamWarmup, calc_train_steps, get_custom_objects\n",
        "# from hyperopt import fmin, hp, tpe, STATUS_OK, Trials\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xGojs4dL6S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = 'drive/My Drive/GoogleQA/Data/'\n",
        "train = pd.read_csv(data_path+'train.csv')\n",
        "test = pd.read_csv(data_path+'test.csv')\n",
        "sub = pd.read_csv(data_path+'sample_submission.csv')\n",
        "aux = pd.read_csv(data_path+'df_qa_extracted.csv')[['qa_id', 'question_viewed_times', 'question_votes', 'answer_counts', 'answer_votes']]\n",
        "\n",
        "target_col = train.columns.tolist()[11:42]\n",
        "train['question'] = train['question_title'] + ' ' + train['question_body']\n",
        "test['question'] = test['question_title'] + ' ' + test['question_body']\n",
        "train = train.merge(aux, how='left', on='qa_id')\n",
        "train = train.fillna(aux.median())\n",
        "# def aux_build(df):\n",
        "#     aux = pd.get_dummies(df['category'], drop_first=True)\n",
        "#     aux['stackexchange'] = df.host.str.contains('stackexchange').astype('int32')\n",
        "#     aux['stackoverflow'] = df.host.str.contains('stackoverflow').astype('int32')\n",
        "#     return aux\n",
        "# train_aux, test_aux = aux_build(train), aux_build(test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPkHK5JvMJpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAXLEN = 512 #@param {type:\"slider\", min:128, max:512, step:32}\n",
        "BATCH_SIZE = 4 #@param {type:'slider', min:1, max:32, step:1}\n",
        "NUM_EPOCHS = 3\n",
        "NUM_CLASSES = 30\n",
        "LR = 5e-5\n",
        "MIN_LR = 0\n",
        "model_path = 'bert_base_uncased' #@param ['bert_base_uncased', 'bert_base_cased', 'bert_large_uncased', 'albert_base']\n",
        "save_model = 'bbu' #@param ['bbu', 'bbc', 'blu', 'tmp', 'use']\n",
        "CASED = False #@param ['True', 'False'] {type:\"raw\"}\n",
        "# OUTPUT_TRAIN = 'train_bert_ipredcv1415_oof.csv'\n",
        "# OUTPUT_TEST = 'test_bert_large.npy'\n",
        "# model_path = 'uncased_L-12_H-768_A-12' #@param ['uncased_L-12_H-768_A-12', 'wwm_uncased_L-24_H-1024_A-16', 'uncased_L-24_H-1024_A-16']\n",
        "# target_q_col = train.columns.tolist()[11:32]\n",
        "# target_a_col = train.columns.tolist()[32:42]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MknUuh8pFpq0",
        "colab_type": "text"
      },
      "source": [
        "## Bert tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb2llbNDMhVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict = {}\n",
        "with codecs.open(os.path.join(model_path, 'assets/vocab.txt'), 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "tokenizer = Tokenizer(token_dict, cased=CASED)\n",
        "\n",
        "def convert_data(data_df, branch='training'):\n",
        "    data_df = data_df.reset_index(drop=True)\n",
        "    global tokenizer\n",
        "    global MAXLEN\n",
        "    global target_col\n",
        "    ids, segments = [], []\n",
        "    # q_title, q_body, answer = [], [], []\n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        a, b = tokenizer.encode(data_df.loc[i, 'question'], data_df.loc[i, 'answer'])\n",
        "        ids.append(a)\n",
        "        segments.append(b)\n",
        "    aux = data_df[['question_viewed_times', 'question_votes', 'answer_counts', 'answer_votes']]\n",
        "    aux = aux.apply(lambda x: (x - x.mean()) / x.std())             \n",
        "    if branch == 'training':\n",
        "        targets = data_df[target_col]\n",
        "        # return [q_title, q_body], np.array(targets)\n",
        "        return [ids, segments], np.array(aux, dtype='float32'), np.array(targets)\n",
        "    else:\n",
        "        return [ids, segments], np.array(aux, dtype='float32')\n",
        "        # return [q_title, q_body]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh7qwb8ZMlbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"## Data Generator\"\"\"\n",
        "def seq_padding(X, padding=0):\n",
        "    # L = [len(x) for x in X]\n",
        "    # ML = min(max(L), MAXLEN)\n",
        "    ML = MAXLEN\n",
        "    out = np.array([np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x[:ML] for x in X])\n",
        "    return tf.convert_to_tensor(out, dtype=tf.int32)\n",
        "    \n",
        "def get_masks(X, padding=0):\n",
        "    # L = [len(x) for x in X]\n",
        "    # ML = min(max(L), MAXLEN)\n",
        "    ML = MAXLEN\n",
        "    out = np.array([np.concatenate([[1]*len(x), [padding] * (ML - len(x))]) if len(x) < ML else [1]*ML for x in X])\n",
        "    return tf.convert_to_tensor(out, dtype=tf.int32)\n",
        "\n",
        "class data_generator:\n",
        "    def __init__(self, data, batch_size=BATCH_SIZE, branch='train'):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.branch = branch\n",
        "        # self.q_a = q_a\n",
        "        self.steps = len(self.data) // self.batch_size\n",
        "        if len(self.data) % self.batch_size != 0:\n",
        "            self.steps += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "\n",
        "    def __iter__(self):\n",
        "        while True:\n",
        "            if self.branch == 'train':\n",
        "                np.random.shuffle(self.data)\n",
        "            for i in range(self.steps):\n",
        "                d = self.data[i * self.batch_size: (i + 1) * self.batch_size]\n",
        "                X1 = seq_padding([x[0] for x in d])\n",
        "                X2 = get_masks([x[0] for x in d])    \n",
        "                X3 = seq_padding([x[1] for x in d])\n",
        "                # X3 = np.zeros_like(X1)\n",
        "\n",
        "                aux = tf.convert_to_tensor([x[2] for x in d], dtype=tf.float32)\n",
        "                if self.branch == 'test':\n",
        "                    # aux = np.array([x[3] for x in d])\n",
        "                    yield [X1, X2, X3]\n",
        "                    # yield [X1, X2, X3, X4, X5, X6]\n",
        "                else:\n",
        "                    Y = tf.convert_to_tensor([x[3] for x in d], dtype=tf.float32)\n",
        "                    # aux = np.array([x[4] for x in d])\n",
        "                    yield [X1, X2, X3], [Y, aux] \n",
        "                    # yield [X1, X2, X3, X4, X5, X6], Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZvVEWF62IdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_build(len_train):\n",
        "    global NUM_CLASSES\n",
        "    global BATCH_SIZE\n",
        "    global NUM_EPOCHS\n",
        "    global MIN_LR\n",
        "    global LR\n",
        "    global MAXLEN\n",
        "    global model_path\n",
        "    # global train_aux\n",
        " \n",
        "    q_in = keras.layers.Input(shape=(MAXLEN,), dtype=tf.int32, name=\"q_input_word_ids\")\n",
        "    q2_in = keras.layers.Input(shape=(MAXLEN,), dtype=tf.int32, name=\"q_input_masks\")\n",
        "    q3_in = keras.layers.Input(shape=(MAXLEN,), dtype=tf.int32, name=\"q_segment_ids\")\n",
        "\n",
        "\n",
        "    bert_layer = hub.KerasLayer(model_path, trainable=True)\n",
        "    _, q_inputs  = bert_layer([q_in, q2_in, q3_in])\n",
        "    # q_outputs = keras.layers.Lambda(lambda x: x[:, 0])(q_inputs)\n",
        "    q_outputs = keras.layers.GlobalAveragePooling1D()(q_inputs)\n",
        "    dense = keras.layers.Dropout(0.2)(q_outputs)\n",
        "\n",
        "    # dense = keras.layers.concatenate([dense, aux_in])\n",
        "    outputs = keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dense)\n",
        "    aux_out = keras.layers.Dense(4)(dense)\n",
        "    model = keras.Model([q_in, q2_in, q3_in], [outputs, aux_out])\n",
        "\n",
        "    decay_steps, warmup_steps = calc_train_steps(\n",
        "        len_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=NUM_EPOCHS,\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss=['binary_crossentropy', 'mean_squared_error'],\n",
        "        loss_weights = [10, 0.25],\n",
        "        optimizer=AdamWarmup(\n",
        "            decay_steps=decay_steps,\n",
        "            warmup_steps=warmup_steps,\n",
        "            lr=LR,\n",
        "            min_lr=MIN_LR,\n",
        "            ))\n",
        "    #      optimizer=keras.optimizers.Adam(LR),\n",
        "    # )\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N56RysQWJ6R1",
        "colab_type": "text"
      },
      "source": [
        "## train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EWLYgjzR5Tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pred = np.zeros((len(test), NUM_CLASSES))\n",
        "kf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "idx = [x for x in kf.split(train, groups=train.question_body)]\n",
        "# tr1, tr2 = train.loc[idx[0][0]], train.loc[idx[0][1]]\n",
        "# tr1 = tr1.reset_index(drop=True)\n",
        "# idx1 = [x for x in kf.split(tr1, groups=tr1.question_body)]\n",
        "\n",
        "\n",
        "def compute_spearmanr(trues, preds):\n",
        "    rhos = []\n",
        "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
        "        rhos.append(spearmanr(col_trues, col_pred).correlation)\n",
        "    return np.mean(rhos)\n",
        "\n",
        "class IntervalEval(keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        global NUM_EPOCHS\n",
        "        global save_model\n",
        "        super(keras.callbacks.Callback, self).__init__()\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # if epoch == 3:\n",
        "        val_pred = self.model.predict_generator(valid_D.__iter__(), len(valid_D), verbose=1)\n",
        "        score = compute_spearmanr(val_y, val_pred[0])\n",
        "        print('Spearman - {:.5f}'.format(score))\n",
        "        # if epoch>=NUM_EPOCHS-1:\n",
        "        #     print('--Save Model--')\n",
        "        #     self.model.save('drive/My Drive/GoogleQA/Models/{:}/{:}-{:}-{:}.h5'.format(save_model, save_model, i, epoch+1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH88F-DJMsTR",
        "colab_type": "code",
        "outputId": "bcf88fcc-7ef5-4a71-8cb7-17c72aec19cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "for i, (tr_idx, val_idx) in enumerate(idx[:1], 1):\n",
        "    print('\\nFold - {:}\\n'.format(i))\n",
        "    tr, val = train.loc[tr_idx], train.loc[val_idx]\n",
        "    # tr_aux, val_aux = train_aux.loc[tr_idx], train_aux.loc[val_idx]\n",
        "    tr_x, tr_aux, tr_y = convert_data(tr)\n",
        "    val_x, val_aux, val_y = convert_data(val)\n",
        "    \n",
        "    model = model_build(len(tr))\n",
        "\n",
        "    train_D = data_generator(list(zip(tr_x[0], tr_x[1], tr_aux, tr_y)))\n",
        "    valid_D = data_generator(list(zip(val_x[0], val_x[1], val_aux, val_y)), branch='valid')\n",
        "    # test_D = data_generator(list(zip(test_x[0], test_x[1])), branch='test')\n",
        "    ieval = IntervalEval()\n",
        "    model.fit_generator(\n",
        "        train_D.__iter__(),\n",
        "        steps_per_epoch=len(train_D),\n",
        "        epochs=NUM_EPOCHS,\n",
        "        callbacks = [ieval]\n",
        "    )\n",
        "\n",
        "    tf.keras.backend.get_session().close()\n",
        "    cfg = tf.ConfigProto()\n",
        "    cfg.gpu_options.allow_growth = True\n",
        "    tf.reset_default_graph()\n",
        "    gc.collect()\n",
        "    tf.keras.backend.set_session(tf.Session(config=cfg))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1061/1216 [=========================>....] - ETA: 1:58 - loss: 4.3655 - dense_2_loss: 0.4119 - dense_3_loss: 0.9876"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSibMadEfi_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "c7b3c918-a3af-4fa1-fc26-24ca6b07166f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "q_input_word_ids (InputLayer)   [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "q_input_masks (InputLayer)      [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "q_segment_ids (InputLayer)      [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   q_input_word_ids[0][0]           \n",
            "                                                                 q_input_masks[0][0]              \n",
            "                                                                 q_segment_ids[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 30)           23070       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            3076        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 109,508,387\n",
            "Trainable params: 109,508,386\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtqtikotHjrY",
        "colab_type": "text"
      },
      "source": [
        "## Bert model stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53aKFzZdFpiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0.8771 / 0.8779 / 0.8786 / 0.8774 / 0.8790\n",
        "tr2_x, tr2_y = convert_data(tr2)\n",
        "valid2_D = data_generator(list(zip(tr2_x[0], tr2_x[1], tr2_y)), branch='valid')\n",
        "model = model_build(len(train), model='bert')\n",
        "ensemble_inputs, ensemble_outputs = [], []\n",
        "# update all layers in all models to not be trainable\n",
        "for i in range(1, 11):\n",
        "    # define filename for this ensemble\n",
        "    filename = 'drive/My Drive/GoogleQA/Models/{:}/{:}-{:}-3.h5'.format(save_model, save_model, i))\n",
        "\n",
        "    # load model from file\n",
        "    model.load_weights(filename)\n",
        "    print('>loaded %s' % filename)\n",
        "\n",
        "    model_pred = model.predict_generator(valid2_D.__iter__(), len(valid2_D), verbose=1)\n",
        "    score = compute_spearmanr(tr2_y, model_pred)\n",
        "    print('Spearman - {:.5f}'.format(score))\n",
        "    for layer in model.layers:\n",
        "        # make not trainable\n",
        "        layer.trainable = False\n",
        "        # rename to avoid 'unique layer name' issue\n",
        "        layer.name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
        "    # define multi-headed input\n",
        "    ensemble_inputs.append(model.input)\n",
        "    # concatenate merge output from each model\n",
        "    ensemble_outputs.append(model.output)\n",
        "    # del model\n",
        "    gc.collect()\n",
        "\n",
        "# build model\n",
        "merge = concatenate(ensemble_outputs)\n",
        "hidden = Dense(100, activation='relu')(merge)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(hidden)\n",
        "stacked_model = Model(inputs=[x for y in ensemble_inputs for x in y], outputs=output)\n",
        "# compile\n",
        "decay_steps, warmup_steps = calc_train_steps(\n",
        "    len(tr2),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=NUM_EPOCHS,\n",
        ")\n",
        "\n",
        "stacked_model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=AdamWarmup(\n",
        "        decay_steps=decay_steps,\n",
        "        warmup_steps=warmup_steps,\n",
        "        lr=LR,\n",
        "        min_lr=MIN_LR,\n",
        "        ))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxpl3Dw_HmL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class data_generator_stacked:\n",
        "    def __init__(self, data, batch_size=BATCH_SIZE, branch='train'):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.branch = branch\n",
        "        self.steps = len(self.data) // self.batch_size\n",
        "        if len(self.data) % self.batch_size != 0:\n",
        "            self.steps += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "\n",
        "    def __iter__(self):\n",
        "        while True:\n",
        "            if self.branch == 'train':\n",
        "                np.random.shuffle(self.data)\n",
        "            for i in range(self.steps):\n",
        "                d = self.data[i * self.batch_size: (i + 1) * self.batch_size]\n",
        "                X1 = seq_padding([x[0] for x in d])\n",
        "                X2 = get_masks([x[0] for x in d])    \n",
        "                X3 = seq_padding([x[1] for x in d])\n",
        "                # X3 = np.zeros_like(X1)\n",
        "\n",
        "                # aux = np.array([x[2] for x in d])\n",
        "                if self.branch == 'test':\n",
        "                    # aux = np.array([x[3] for x in d])\n",
        "                    yield [X1, X2, X3] * 10\n",
        "                    # yield [X1, X2, X3, X4, X5, X6]\n",
        "                else:\n",
        "                    Y = np.array([x[2] for x in d])\n",
        "                    # aux = np.array([x[4] for x in d])\n",
        "                    yield [X1, X2, X3] * 10, Y\n",
        "                    # yield [X1, X2, X3, X4, X5, X6], Y\n",
        "\n",
        "# fit model\n",
        "stack_D = data_generator_stacked(list(zip(tr2_x[0], tr2_x[1], tr2_y)))\n",
        "stacked_model.fit_generator(\n",
        "    stack_D.__iter__(),\n",
        "    steps_per_epoch=len(stack_D),\n",
        "    epochs=NUM_EPOCHS)\n",
        "\n",
        "stack_valid_D = data_generator_stacked(list(zip(tr2_x[0], tr2_x[1], tr2_y)), branch='valid')\n",
        "stacked_pred = stacked_model.predict_generator(stack_valid_D.__iter__(), len(stack_valid_D), verbose=1)\n",
        "print('Spearman - {:.5f}'.format(compute_spearmanr(tr2_y, stacked_pred)))\n",
        "\n",
        "del stacked_model\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRMV2dmrNV4x",
        "colab_type": "text"
      },
      "source": [
        "## USE Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOvLGUbfNX9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# train['sentence'] = train['question'] + ' ' + train['answer']\n",
        "embed1 = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
        "# embed2 = hub.load('https://tfhub.dev/google/nnlm-en-dim128/2')\n",
        "\n",
        "def UniversalEmbedding(x):\n",
        "    return embed1(tf.squeeze(tf.cast(x, tf.string)))\n",
        "\n",
        "# def NNLMEmbedding(x):\n",
        "#     return embed2(tf.squeeze(tf.cast(x, tf.string)))\n",
        "\n",
        "def use_model():\n",
        "    \n",
        "    q = keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "    qb = keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "    a = keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "\n",
        "    def hidden_layer(input_layer):\n",
        "        x = keras.layers.Lambda(UniversalEmbedding, output_shape=(512, ))(input_layer)\n",
        "        # embed2 = keras.layers.Lambda(NNLMEmbedding, output_shape=(128, ))(input_layer)\n",
        "        # embed = keras.layers.concatenate([embed1, embed2])\n",
        "        x = keras.layers.Dropout(0.2)(x)\n",
        "        x = keras.backend.expand_dims(x, axis=1)\n",
        "        # x = keras.layers.Bidirectional(keras.layers.CuDNNLSTM(128, return_sequences=True))(x)\n",
        "        # x = keras.layers.Bidirectional(keras.layers.CuDNNLSTM(128, return_sequences=True))(x)\n",
        "        # GP = keras.layers.GlobalMaxPooling1D()(x)\n",
        "        # GP = keras.layers.Dropout(0.2)(GP)\n",
        "        # AP = keras.layers.GlobalAveragePooling1D()(x)\n",
        "        # AP = keras.layers.Dropout(0.2)(AP)\n",
        "        # hidden = keras.layers.concatenate([GP, AP])\n",
        "        # hidden = keras.layers.add([hidden, keras.layers.Dense(512, activation='relu')(hidden)])\n",
        "        # hidden = keras.layers.add([hidden, keras.layers.Dense(512, activation='relu')(hidden)])\n",
        "\n",
        "        x1 = keras.layers.Bidirectional(keras.layers.CuDNNLSTM(256, return_sequences=True))(x)\n",
        "        x2 = keras.layers.Bidirectional(keras.layers.CuDNNGRU(128, return_sequences=True))(x1)\n",
        "        max_pool1 = keras.layers.GlobalMaxPooling1D()(x1)\n",
        "        max_pool2 = keras.layers.GlobalMaxPooling1D()(x2)\n",
        "        hidden = keras.layers.concatenate([max_pool1, max_pool2])\n",
        "        return hidden\n",
        "\n",
        "    q_embed, qb_embed, a_embed = hidden_layer(q), hidden_layer(qb), hidden_layer(a)\n",
        "    all_embed = keras.layers.concatenate([q_embed, qb_embed, a_embed])\n",
        "    dense = keras.layers.Dense(256, activation='relu')(all_embed)\n",
        "    pred = keras.layers.Dense(30, activation='sigmoid')(dense)\n",
        "    model = keras.Model(inputs=[q, qb, a], outputs=pred)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=5e-3))\n",
        "    # del embed\n",
        "    # gc.collect()\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTIxpMnFNhju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "idx = [x for x in kf.split(train, groups=train.question_body)]\n",
        "def compute_spearmanr(trues, preds):\n",
        "    rhos = []\n",
        "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
        "        rhos.append(spearmanr(col_trues, col_pred).correlation)\n",
        "    return np.mean(rhos)\n",
        "\n",
        "class IntervalEval(keras.callbacks.Callback):\n",
        "    def __init__(self, val_data, label):\n",
        "        super(keras.callbacks.Callback, self).__init__()\n",
        "        self.val_data = val_data\n",
        "        self.score = 0\n",
        "        self.maxscore = 0\n",
        "        self.label = label\n",
        "        self.patience = 3\n",
        "        self.count = 0\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # if epoch == 3:\n",
        "        val_pred = self.model.predict(self.val_data, batch_size=16, verbose=1)\n",
        "        score = compute_spearmanr(self.label, val_pred)\n",
        "        print('Spearman - {:.5f}'.format(score))\n",
        "        if self.maxscore>=0.3:\n",
        "            self.patience=2\n",
        "        if (score < self.score):\n",
        "            self.score = score\n",
        "            self.count+=1\n",
        "            if self.count==self.patience:\n",
        "                self.model.stop_training=True\n",
        "        elif score > self.maxscore:\n",
        "            self.score = score\n",
        "            self.maxscore = score\n",
        "            self.count = 0\n",
        "            if self.maxscore > 0.3:\n",
        "                self.model.save('drive/My Drive/GoogleQA/Models/{:}/use-model-{:}.h5'.format(save_model, i))\n",
        "        else:\n",
        "            self.score = score\n",
        "            self.count = 0\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bd--Dd_QUof",
        "colab_type": "code",
        "outputId": "4a135471-867b-4a2e-ba23-c5fe112ac9d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "    keras.backend.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    for i, (tr_idx, val_idx) in enumerate(idx, 1):\n",
        "        print('\\nFold - {:}\\n'.format(i))\n",
        "        tr, val = train.loc[tr_idx], train.loc[val_idx]\n",
        "        tr_x = [tr['question_title'], tr['question_body'], tr['answer']]\n",
        "        val_x = [val['question_title'], val['question_body'], val['answer']]\n",
        "        ieval = IntervalEval(val_data=val_x, label=val[target_col].values)\n",
        "        model = use_model()\n",
        "        history = model.fit(\n",
        "            tr_x,\n",
        "            tr[target_col],\n",
        "            epochs=100, \n",
        "            batch_size=16,\n",
        "            callbacks=[ieval])\n",
        "        del model, tr, val, tr_x, val_x\n",
        "        gc.collect()\n",
        "\n",
        "# with tf.Session() as session:\n",
        "#     keras.backend.set_session(session)\n",
        "#     session.run(tf.global_variables_initializer())  \n",
        "#     session.run(tf.tables_initializer())\n",
        "#     model.load_weights('use-model-1.h5')\n",
        "#     preds = model.predict(val['sentence'], batch_size=16, verbose=1)\n",
        "#     score=compute_spearmanr(val[target_col].values, preds)\n",
        "#     print('Spearman - {:.5f}'.format(score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold - 1\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 33s 27ms/sample\n",
            "Spearman - 0.35849\n",
            "4863/4863 [==============================] - 170s 35ms/sample - loss: 0.3946\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36453\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3720\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37807\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3628\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37832\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3549\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37996\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3462\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37266\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3358\n",
            "Epoch 7/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36546\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3244\n",
            "\n",
            "Fold - 2\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 34s 28ms/sample\n",
            "Spearman - 0.33703\n",
            "4863/4863 [==============================] - 156s 32ms/sample - loss: 0.3924\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.34534\n",
            "4863/4863 [==============================] - 88s 18ms/sample - loss: 0.3710\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36068\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3621\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36306\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3539\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36120\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3444\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35571\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3338\n",
            "\n",
            "Fold - 3\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 34s 28ms/sample\n",
            "Spearman - 0.34580\n",
            "4863/4863 [==============================] - 160s 33ms/sample - loss: 0.3934\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36574\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3713\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37321\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3624\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36790\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3541\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 15s 13ms/sample\n",
            "Spearman - 0.37437\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3454\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35966\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3339\n",
            "Epoch 7/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35308\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3227\n",
            "\n",
            "Fold - 4\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 35s 29ms/sample\n",
            "Spearman - 0.34625\n",
            "4863/4863 [==============================] - 160s 33ms/sample - loss: 0.3937\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35942\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3718\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36250\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3624\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36419\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3542\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36604\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3455\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 14ms/sample\n",
            "Spearman - 0.35845\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3351\n",
            "Epoch 7/100\n",
            "1216/1216 [==============================] - 16s 14ms/sample\n",
            "Spearman - 0.36201\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3232\n",
            "Epoch 8/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35785\n",
            "4863/4863 [==============================] - 85s 17ms/sample - loss: 0.3119\n",
            "Epoch 9/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35012\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3011\n",
            "\n",
            "Fold - 5\n",
            "\n",
            "Train on 4864 samples\n",
            "Epoch 1/100\n",
            "1215/1215 [==============================] - 37s 30ms/sample\n",
            "Spearman - 0.34068\n",
            "4864/4864 [==============================] - 168s 34ms/sample - loss: 0.3943\n",
            "Epoch 2/100\n",
            "1215/1215 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35529\n",
            "4864/4864 [==============================] - 86s 18ms/sample - loss: 0.3726\n",
            "Epoch 3/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35790\n",
            "4864/4864 [==============================] - 86s 18ms/sample - loss: 0.3637\n",
            "Epoch 4/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35886\n",
            "4864/4864 [==============================] - 86s 18ms/sample - loss: 0.3551\n",
            "Epoch 5/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36241\n",
            "4864/4864 [==============================] - 87s 18ms/sample - loss: 0.3468\n",
            "Epoch 6/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35775\n",
            "4864/4864 [==============================] - 85s 17ms/sample - loss: 0.3355\n",
            "Epoch 7/100\n",
            "1215/1215 [==============================] - 16s 14ms/sample\n",
            "Spearman - 0.34976\n",
            "4864/4864 [==============================] - 85s 17ms/sample - loss: 0.3240\n",
            "\n",
            "Fold - 6\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 37s 30ms/sample\n",
            "Spearman - 0.33484\n",
            "4863/4863 [==============================] - 169s 35ms/sample - loss: 0.3942\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36367\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3720\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36417\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3626\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36823\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3540\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36329\n",
            "4863/4863 [==============================] - 85s 17ms/sample - loss: 0.3453\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35710\n",
            "4863/4863 [==============================] - 82s 17ms/sample - loss: 0.3342\n",
            "\n",
            "Fold - 7\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 36s 30ms/sample\n",
            "Spearman - 0.34222\n",
            "4863/4863 [==============================] - 168s 35ms/sample - loss: 0.3936\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35259\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3722\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.34803\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3635\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35987\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3550\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 15s 13ms/sample\n",
            "Spearman - 0.36029\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3457\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35276\n",
            "4863/4863 [==============================] - 83s 17ms/sample - loss: 0.3352\n",
            "Epoch 7/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.34791\n",
            "4863/4863 [==============================] - 83s 17ms/sample - loss: 0.3231\n",
            "\n",
            "Fold - 8\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 37s 30ms/sample\n",
            "Spearman - 0.33639\n",
            "4863/4863 [==============================] - 172s 35ms/sample - loss: 0.3933\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 15s 13ms/sample\n",
            "Spearman - 0.36531\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3722\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 15s 13ms/sample\n",
            "Spearman - 0.36391\n",
            "4863/4863 [==============================] - 83s 17ms/sample - loss: 0.3632\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37153\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3548\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36293\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3456\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35556\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3350\n",
            "\n",
            "Fold - 9\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 38s 31ms/sample\n",
            "Spearman - 0.33901\n",
            "4863/4863 [==============================] - 179s 37ms/sample - loss: 0.3935\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35072\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3710\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36947\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3626\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 14ms/sample\n",
            "Spearman - 0.36432\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3540\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36742\n",
            "4863/4863 [==============================] - 85s 17ms/sample - loss: 0.3452\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35627\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3352\n",
            "Epoch 7/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35086\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3234\n",
            "\n",
            "Fold - 10\n",
            "\n",
            "Train on 4864 samples\n",
            "Epoch 1/100\n",
            "1215/1215 [==============================] - 39s 32ms/sample\n",
            "Spearman - 0.35438\n",
            "4864/4864 [==============================] - 184s 38ms/sample - loss: 0.3930\n",
            "Epoch 2/100\n",
            "1215/1215 [==============================] - 16s 14ms/sample\n",
            "Spearman - 0.37118\n",
            "4864/4864 [==============================] - 87s 18ms/sample - loss: 0.3713\n",
            "Epoch 3/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36850\n",
            "4864/4864 [==============================] - 86s 18ms/sample - loss: 0.3621\n",
            "Epoch 4/100\n",
            "1215/1215 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37393\n",
            "4864/4864 [==============================] - 91s 19ms/sample - loss: 0.3541\n",
            "Epoch 5/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.37396\n",
            "4864/4864 [==============================] - 89s 18ms/sample - loss: 0.3447\n",
            "Epoch 6/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36964\n",
            "4864/4864 [==============================] - 87s 18ms/sample - loss: 0.3342\n",
            "Epoch 7/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35713\n",
            "4864/4864 [==============================] - 87s 18ms/sample - loss: 0.3228\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}