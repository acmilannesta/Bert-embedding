{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoogleQA.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acmilannesta/Bert-embedding/blob/master/GoogleQA_tfhub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D82bieSpLcuc",
        "colab_type": "code",
        "outputId": "c668466c-31e9-4028-f6dc-14973f69028a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Dec 25 23:45:11 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JErzYVOxLtWo",
        "colab_type": "code",
        "outputId": "c00bbce6-4c5b-4df2-e7a0-c2bedefdbb58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "# bert uncased base\n",
        "!wget https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1?tf-hub-format=compressed -O bbu\n",
        "!mkdir bert_base_uncased\n",
        "!tar -xzf bbu -C bert_base_uncased\n",
        "\n",
        "# bert cased base\n",
        "!wget https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1?tf-hub-format=compressed -O bbc\n",
        "!mkdir bert_base_cased\n",
        "!tar -xzf bbc -C bert_base_cased\n",
        "\n",
        "# albert base\n",
        "!wget https://tfhub.dev/google/albert_base/1?tf-hub-format=compressed -O ab\n",
        "!mkdir albert_base\n",
        "!tar -xzf ab -C albert_base\n",
        "\n",
        "# bert uncased large\n",
        "!wget https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1?tf-hub-format=compressed -O blu\n",
        "!mkdir bert_large_uncased\n",
        "!tar -xzf blu -C bert_large_uncased"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-25 23:45:20--  https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1?tf-hub-format=compressed\n",
            "Resolving tfhub.dev (tfhub.dev)... 64.233.189.139, 64.233.189.101, 64.233.189.113, ...\n",
            "Connecting to tfhub.dev (tfhub.dev)|64.233.189.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/tfhub-modules/tensorflow/bert_en_uncased_L-12_H-768_A-12/1.tar.gz [following]\n",
            "--2019-12-25 23:45:20--  https://storage.googleapis.com/tfhub-modules/tensorflow/bert_en_uncased_L-12_H-768_A-12/1.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.204.128, 2404:6800:4008:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405800905 (387M) [application/x-tar]\n",
            "Saving to: ‘bbu’\n",
            "\n",
            "bbu                 100%[===================>] 387.00M  91.1MB/s    in 5.2s    \n",
            "\n",
            "2019-12-25 23:45:26 (74.5 MB/s) - ‘bbu’ saved [405800905/405800905]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBrwK8dwLyw8",
        "colab_type": "code",
        "outputId": "16681340-7052-4f6a-8816-41450e170a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaDm4NWvLp_J",
        "colab_type": "code",
        "outputId": "523624fc-31ce-4b2a-9168-8711dabaaeb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import sys\n",
        "sys.path.insert(1, '/content/drive/My Drive/GoogleQA')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, gc\n",
        "import codecs\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.backend import set_session\n",
        "# from keras.callbacks import Callback\n",
        "# from keras.models import Model, load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GroupKFold, KFold, RepeatedKFold\n",
        "from scipy.stats import spearmanr\n",
        "from tqdm import tqdm\n",
        "import tensorflow_hub as hub\n",
        "# from albert_tokenization import FullTokenizer\n",
        "from tokenizer import Tokenizer\n",
        "from warmup_v2 import AdamWarmup, calc_train_steps\n",
        "tf.get_logger().setLevel('ERROR') \n",
        "# from keras_bert import load_trained_model_from_checkpoint, Tokenizer, AdamWarmup, calc_train_steps, get_custom_objects\n",
        "from hyperopt import fmin, hp, tpe, STATUS_OK, Trials\n",
        "from functools import partial\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xGojs4dL6S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = 'drive/My Drive/GoogleQA/Data/'\n",
        "aux_path = 'drive/My Drive/GoogleQA/Web Scrap/'\n",
        "train = pd.read_csv(data_path+'train.csv')\n",
        "test = pd.read_csv(data_path+'test.csv')\n",
        "sub = pd.read_csv(data_path+'sample_submission.csv')\n",
        "# qa_aux = pd.read_csv(aux_path+'df_qa_extracted.csv')[['qa_id', 'question_viewed_times', 'question_votes', 'answer_counts', 'answer_votes']]\n",
        "# quser_aux = pd.read_csv(aux_path+'df_question_user_extracted.csv')\n",
        "# auser_aux = pd.read_csv(aux_path+'df_answer_user_extracted.csv')\n",
        "target_col = train.columns.tolist()[11:42]\n",
        "\n",
        "train['class'] = train.host.apply(lambda x: x.split('.')[0])\n",
        "train['question_title'] = train['category']+' '+train['class']+' '+train['question_title']#+' '+train['question_body']\n",
        "test['class'] = test.host.apply(lambda x: x.split('.')[0])\n",
        "test['question_title'] = test['category']+' '+test['class']+' '+test['question_title']#+' '+test['question_body']\n",
        " \n",
        "# category_encoder = LabelEncoder().fit(pd.concat([train['category'], test['category']]))\n",
        "# host_encoder = LabelEncoder().fit(pd.concat([train['host'], test['host']]))\n",
        "# train['category'] = category_encoder.transform(train['category'])\n",
        "# test['category'] = category_encoder.transform(test['category'])\n",
        "# train['host'] = host_encoder.transform(train['host'])\n",
        "# test['host'] = host_encoder.transform(test['host'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPkHK5JvMJpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAXLEN = 512 #@param {type:\"slider\", min:128, max:512, step:32}\n",
        "BATCH_SIZE = 4 #@param {type:'slider', min:1, max:32, step:1}\n",
        "NUM_EPOCHS = 3\n",
        "NUM_CLASSES = 30\n",
        "NUM_AUX = 6\n",
        "LR = 5e-5\n",
        "MIN_LR = 0\n",
        "model_path = 'bert_base_uncased' #@param ['bert_base_uncased', 'bert_base_cased', 'bert_large_uncased', 'albert_base']\n",
        "save_path = 'bbu4'\n",
        "save_model = 'bbu4' \n",
        "CASED = False #@param ['True', 'False'] {type:\"raw\"}\n",
        "# OUTPUT_TRAIN = 'train_bert_ipredcv1415_oof.csv'\n",
        "# OUTPUT_TEST = 'test_bert_large.npy'\n",
        "# model_path = 'uncased_L-12_H-768_A-12' #@param ['uncased_L-12_H-768_A-12', 'wwm_uncased_L-24_H-1024_A-16', 'uncased_L-24_H-1024_A-16']\n",
        "# target_q_col = train.columns.tolist()[11:32]\n",
        "# target_a_col = train.columns.tolist()[32:42]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MknUuh8pFpq0",
        "colab_type": "text"
      },
      "source": [
        "## Bert tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWJBpOFN7FCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _trim_input(title, question, answer, max_sequence_length=MAXLEN,\n",
        "                t_max_len=20, q_max_len=246, a_max_len=246):\n",
        "    # t = tokenizer.tokenize(title)\n",
        "    # q = tokenizer.tokenize(question)\n",
        "    # a = tokenizer.tokenize(answer)\n",
        "    t_len = len(title)\n",
        "    q_len = len(question)\n",
        "    a_len = len(answer)\n",
        "    if (t_len + q_len + a_len) > max_sequence_length:\n",
        "        if t_max_len > t_len:\n",
        "            t_new_len = t_len\n",
        "            a_max_len = a_max_len + np.floor((t_max_len - t_len) / 2)\n",
        "            q_max_len = q_max_len + np.ceil((t_max_len - t_len) / 2)\n",
        "        else:\n",
        "            t_new_len = t_max_len\n",
        "        if a_max_len > a_len:\n",
        "            a_new_len = a_len\n",
        "            q_new_len = q_max_len + (a_max_len - a_len)\n",
        "        elif q_max_len > q_len:\n",
        "            a_new_len = a_max_len + (q_max_len - q_len)\n",
        "            q_new_len = q_len\n",
        "        else:\n",
        "            a_new_len = a_max_len\n",
        "            q_new_len = q_max_len\n",
        "        if t_new_len + a_new_len + q_new_len!= max_sequence_length:\n",
        "            raise ValueError(\"New sequence length should be %d, but is %d\"\n",
        "                    % (max_sequence_length, (t_new_len + a_new_len + q_new_len)))\n",
        "        head_t_new_len = int(0.25 * t_new_len)\n",
        "        tail_t_new_len = int(t_new_len - head_t_new_len)\n",
        "\n",
        "        head_q_new_len = int(0.25 * q_new_len)\n",
        "        tail_q_new_len = int(q_new_len - head_q_new_len)\n",
        "\n",
        "        head_a_new_len = int(0.25 * a_new_len)\n",
        "        tail_a_new_len = int(a_new_len - head_a_new_len)\n",
        "\n",
        "        title = title[:head_t_new_len] + title[-tail_t_new_len:]\n",
        "        question = question[:head_q_new_len] + question[-tail_q_new_len:]\n",
        "        answer = answer[:head_a_new_len] + answer[-tail_a_new_len:]\n",
        "\n",
        "    return title, question, answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb2llbNDMhVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict = {}\n",
        "with codecs.open(os.path.join(model_path, 'assets/vocab.txt'), 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "tokenizer = Tokenizer(token_dict, cased=CASED)\n",
        "\n",
        "def convert_data(data_df, branch='training'):\n",
        "    data_df = data_df.reset_index(drop=True)\n",
        "    global tokenizer\n",
        "    global MAXLEN\n",
        "    global target_col\n",
        "    ids, segments = [], []\n",
        "    # q_title, q_body, answer = [], [], []\n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        a, _ = tokenizer.encode(data_df.loc[i, 'question_title'])\n",
        "        b, _ = tokenizer.encode(data_df.loc[i, 'question_body'])\n",
        "        c, _ = tokenizer.encode(data_df.loc[i, 'answer'])\n",
        "        # if len(a) + len(b) >512:\n",
        "        #     if (len(a) > 256) & (len(b) > 256):\n",
        "        #         a, b = a[:256], b[:256]\n",
        "        #     elif len(a) > len(b):\n",
        "        #         a = a[:(512-len(b))]\n",
        "        #     elif len(a) <= len(b):\n",
        "        #         b = b[:(512-len(a))]\n",
        "        a, b, c = _trim_input(a, b, c)\n",
        "        ids.append(a + b + c)\n",
        "        segments.append([0] * len(a + b) + [1] * len(c))\n",
        "    # aux = data_df[['question_viewed_times', 'question_votes', 'answer_counts', 'answer_votes', 'answer_user_reputation', 'question_user_reputation']]\n",
        "    # aux = aux.apply(lambda x: (x - x.mean()) / x.std())    \n",
        "    # aux = data_df[['category', 'host']]        \n",
        "    if branch == 'training':\n",
        "        targets = data_df[target_col]\n",
        "        return [ids, segments], np.array(targets)\n",
        "        # return [ids, segments], np.array(aux, dtype='float32'), np.array(targets)\n",
        "    else:\n",
        "        # return [ids, segments], np.array(aux, dtype='float32')\n",
        "        return [ids, segments]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh7qwb8ZMlbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"## Data Generator\"\"\"\n",
        "def seq_padding(X, padding=0):\n",
        "    L = [len(x) for x in X]\n",
        "    ML = min(max(L), MAXLEN)\n",
        "    # ML = MAXLEN\n",
        "    out = np.array([np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x[:ML] for x in X])\n",
        "    return tf.convert_to_tensor(out, dtype=tf.int32)\n",
        "    \n",
        "def get_masks(X, padding=0):\n",
        "    L = [len(x) for x in X]\n",
        "    ML = min(max(L), MAXLEN)\n",
        "    # ML = MAXLEN\n",
        "    out = np.array([np.concatenate([[1]*len(x), [padding] * (ML - len(x))]) if len(x) < ML else [1]*ML for x in X])\n",
        "    return tf.convert_to_tensor(out, dtype=tf.int32)\n",
        "\n",
        "class data_generator:\n",
        "    def __init__(self, data, batch_size=BATCH_SIZE, branch='train'):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.branch = branch\n",
        "        # self.q_a = q_a\n",
        "        self.steps = len(self.data) // self.batch_size\n",
        "        if len(self.data) % self.batch_size != 0:\n",
        "            self.steps += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "\n",
        "    def __iter__(self):\n",
        "        while True:\n",
        "            if self.branch == 'train':\n",
        "                np.random.shuffle(self.data)\n",
        "            for i in range(self.steps):\n",
        "                d = self.data[i * self.batch_size: (i + 1) * self.batch_size]\n",
        "                X1 = seq_padding([x[0] for x in d])\n",
        "                X2 = get_masks([x[0] for x in d])    \n",
        "                X3 = seq_padding([x[1] for x in d])\n",
        "                # X3 = np.zeros_like(X1)\n",
        "                # aux1 = tf.convert_to_tensor([x[2][:, 0] for x in d], dtype=tf.int32)\n",
        "                # aux2 = tf.convert_to_tensor([x[2][:, 1] for x in d], dtype=tf.int32)\n",
        "                if self.branch == 'test':\n",
        "                    # aux = np.array([x[3] for x in d])\n",
        "                    yield [X1, X2, X3]\n",
        "                    # yield [X1, X2, X3, X4, X5, X6]\n",
        "                else:\n",
        "                    Y = tf.convert_to_tensor([x[2] for x in d], dtype=tf.float32)\n",
        "                    # aux = np.array([x[4] for x in d])\n",
        "                    yield [X1, X2, X3], Y\n",
        "                    # yield [X1, X2, X3, aux1, aux2], Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZvVEWF62IdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_build(len_train, lr=LR, epochs=NUM_EPOCHS, bert_trainable=True):\n",
        "    global NUM_CLASSES\n",
        "    global BATCH_SIZE\n",
        "    global NUM_EPOCHS\n",
        "    global MIN_LR\n",
        "    # global LR\n",
        "    global MAXLEN\n",
        "    global model_path\n",
        "    global NUM_AUX\n",
        " \n",
        "    q_in = keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"q_input_word_ids\")\n",
        "    q2_in = keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"q_input_masks\")\n",
        "    q3_in = keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"q_segment_ids\")\n",
        "    # input_category = keras.layers.Input((1,), dtype=tf.int32, name='input_category')\n",
        "    # input_host = tf.keras.layers.Input((1,), dtype=tf.int32, name='input_host')\n",
        "\n",
        "    bert_layer = hub.KerasLayer(model_path, trainable=bert_trainable)\n",
        "    _, q_inputs  = bert_layer([q_in, q2_in, q3_in])\n",
        "    q_outputs = keras.layers.GlobalAveragePooling1D()(q_inputs)\n",
        "    dense = keras.layers.Dropout(0.1)(q_outputs)\n",
        "\n",
        "    # category_emb = keras.layers.Embedding(input_dim=len(category_encoder.classes_)+1, output_dim=32)(input_category)\n",
        "    # category_emb = keras.layers.SpatialDropout1D(0.1)(category_emb)\n",
        "\n",
        "    # host_emb = keras.layers.Embedding(input_dim=len(category_encoder.classes_)+1, output_dim=32)(input_host)\n",
        "    # host_emb = keras.layers.SpatialDropout1D(0.1)(host_emb)\n",
        "\n",
        "    # features_dense = keras.layers.concatenate([category_emb, host_emb], axis=1)\n",
        "    # features_dense = keras.layers.Flatten()(features_dense)\n",
        "\n",
        "    # dense = keras.layers.concatenate([dense, features_dense])\n",
        "    outputs = keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dense)\n",
        "    # aux_out = keras.layers.Dense(NUM_AUX)(dense)\n",
        "    model = keras.Model([q_in, q2_in, q3_in], [outputs])\n",
        "\n",
        "    decay_steps, warmup_steps = calc_train_steps(\n",
        "        len_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=epochs,\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss=['binary_crossentropy'],\n",
        "        # loss_weights = [10, 0.25],\n",
        "        optimizer=AdamWarmup(\n",
        "            decay_steps=decay_steps,\n",
        "            warmup_steps=warmup_steps,\n",
        "            lr=lr,\n",
        "            min_lr=MIN_LR,\n",
        "            ))\n",
        "    #      optimizer=keras.optimizers.Adam(LR),\n",
        "    # )\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N56RysQWJ6R1",
        "colab_type": "text"
      },
      "source": [
        "## train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EWLYgjzR5Tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pred = np.zeros((len(test), NUM_CLASSES))\n",
        "# kf = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1627)\n",
        "kf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "idx = [x for x in kf.split(train, groups=train.question_body)]\n",
        "\n",
        "def compute_spearmanr(trues, preds):\n",
        "    rhos = []\n",
        "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
        "        rhos.append(spearmanr(col_trues, col_pred).correlation)\n",
        "    return np.mean(rhos)\n",
        "\n",
        "class IntervalEval(keras.callbacks.Callback):\n",
        "    def __init__(self, stage=1, rho=-1):\n",
        "        global NUM_EPOCHS\n",
        "        global save_model\n",
        "        super(keras.callbacks.Callback, self).__init__()\n",
        "        self.stage = stage\n",
        "        self.rho = rho\n",
        "        # self.rho = rho\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        val_pred = self.model.predict_generator(valid_D.__iter__(), len(valid_D), verbose=1)\n",
        "        score = compute_spearmanr(val_y, val_pred)\n",
        "        print('Spearman - {:.5f}'.format(score))\n",
        "        # if self.stage==1:\n",
        "        if score > self.rho:\n",
        "            self.rho = score\n",
        "            print('--Save Model--')\n",
        "            self.model.save('drive/My Drive/GoogleQA/Models/{:}/{:}-{:}-{:}.h5'.format(save_path, save_model, i, self.stage))\n",
        "        # elif self.stage==2:\n",
        "        #     if score > self.rho:\n",
        "        #         self.rho = score\n",
        "        #         print('--Save Model--')\n",
        "        #         self.model.save('drive/My Drive/GoogleQA/Models/{:}/{:}-{:}-3.h5'.format('bbu4', 'bbu4', i))\n",
        "        #     else:\n",
        "        #         self.model.stop_training = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH88F-DJMsTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (tr_idx, val_idx) in enumerate(idx[4:5], 5):\n",
        "    keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    print('\\nFold - {:}\\n'.format(i))\n",
        "    tr, val = train.loc[tr_idx], train.loc[val_idx]\n",
        "    # tr_aux, val_aux = train_aux.loc[tr_idx], train_aux.loc[val_idx]\n",
        "    tr_x, tr_y = convert_data(tr)\n",
        "    val_x, val_y = convert_data(val)\n",
        "    train_D = data_generator(list(zip(tr_x[0], tr_x[1], tr_y)))\n",
        "    valid_D = data_generator(list(zip(val_x[0], val_x[1], val_y)), branch='valid')\n",
        "    \n",
        "    # stage 1 fine tunning\n",
        "    # ieval = IntervalEval()\n",
        "    # model = model_build(len(tr))\n",
        "    # model.fit_generator(\n",
        "    #     train_D.__iter__(),\n",
        "    #     steps_per_epoch=len(train_D),\n",
        "    #     epochs=NUM_EPOCHS,\n",
        "    #     callbacks = [ieval]\n",
        "    # )   \n",
        "\n",
        "    # stage 2 fine tunning\n",
        "    ieval = IntervalEval(stage=2, rho=0.39059)\n",
        "    model = model_build(len(tr), lr=1e-3, epochs=4, bert_trainable=False)\n",
        "    model.load_weights('drive/My Drive/GoogleQA/Models/{:}/{:}-{:}-1.h5'.format(save_path, save_model, i))\n",
        "\n",
        "    # test_D = data_generator(list(zip(test_x[0], test_x[1])), branch='test')\n",
        "    \n",
        "    model.fit_generator(\n",
        "        train_D.__iter__(),\n",
        "        steps_per_epoch=len(train_D),\n",
        "        epochs=4,\n",
        "        callbacks = [ieval]\n",
        "    )\n",
        "\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWNNEfR8qnG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# oof-prediction\n",
        "model = model_build(len(tr), bert_trainable=False)\n",
        "oof_pred = train[['qa_id']+target_col].copy()\n",
        "oof_pred[target_col] = 0\n",
        "\n",
        "for i, (tr_idx, val_idx) in enumerate(idx[1:], 2):\n",
        "    print('\\nFold - {:}\\n'.format(i))\n",
        "    tr, val = train.loc[tr_idx], train.loc[val_idx]\n",
        "\n",
        "    val_x, val_y = convert_data(val)\n",
        "    valid_D = data_generator(list(zip(val_x[0], val_x[1], val_y)), branch='valid')\n",
        "\n",
        "    model.load_weights('drive/My Drive/GoogleQA/Models/{}/{}-{}-2.h5'.format(save_path, save_model, i))\n",
        "    val_pred = model.predict_generator(valid_D.__iter__(), len(valid_D), verbose=1)\n",
        "    oof_pred.loc[val_idx, target_col] += val_pred /2\n",
        "\n",
        "    \n",
        "    score = compute_spearmanr(val_y, val_pred)\n",
        "    print('Spearman - {:.5f}'.format(score))\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "oof_pred.to_csv('drive/My Drive/GoogleQA/Data/train_oof_pred_bbu4.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JudYQut5qdbJ",
        "colab_type": "text"
      },
      "source": [
        "## oof-prediction hyperparameterize\n",
        "1. Number of bins\n",
        "2. Cutoffs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFnmddugkiwX",
        "colab_type": "text"
      },
      "source": [
        "### Just use \"90\" transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cegkGSpSHCx",
        "colab_type": "code",
        "outputId": "16d69fa3-de18-4527-d301-095cdd92a5ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# bbu3: 0.42130\n",
        "# bbu4: 0.43406\n",
        "oof_pred = pd.read_csv('drive/My Drive/GoogleQA/Data/train_oof_pred_bbu4.csv')\n",
        "score = compute_spearmanr(np.floor(oof_pred[target_col].values*90)/90, train[target_col].values)\n",
        "print('Total Score: {:.5f}'.format(score))\n",
        "\n",
        "# just using \"90\" transformation\n",
        "scores = []\n",
        "for col, col_trues, col_pred in zip(target_col, train[target_col].values.T, (np.floor(oof_pred[target_col].values *90)/90).T):\n",
        "    corr = spearmanr(col_trues, col_pred).correlation\n",
        "    print('{} - {:.5f}'.format(col, corr))\n",
        "    scores.append(corr)\n",
        "\n",
        "hyper1 = pd.DataFrame(dict(col=target_col, score1=scores))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Score: 0.43406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w3-YFHgklQL",
        "colab_type": "text"
      },
      "source": [
        "### Use lower (to 0) resetting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJXnyWxJgag6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "91f8264b-fdd2-40a5-e8b5-9877621dd895"
      },
      "source": [
        "# Just use zero\n",
        "corrparams = {\n",
        "    'lower': hp.randint('lower', len(oof_pred)),\n",
        "    # 'upper': hp.randint('upper', len(oof_pred))\n",
        "    }\n",
        "def f_min(params, col):\n",
        "    tmp = oof_pred.copy()[col].values\n",
        "    loweridx = tmp.argsort()[:params['lower']]\n",
        "    # upperidx = tmp.argsort()[-params['upper']:]\n",
        "    tmp[loweridx] = 0\n",
        "    # tmp[upperidx] = 1\n",
        "    score = spearmanr(train[col].values, tmp).correlation\n",
        "    return {'loss': -round(score, 5), 'status': STATUS_OK}\n",
        "\n",
        "score, lower = [], []\n",
        "for col in target_col:\n",
        "    f = partial(f_min, col=col)\n",
        "    trials = Trials()\n",
        "    best = fmin(f, corrparams, tpe.suggest, 100, rstate=np.random.RandomState(0), trials=trials, show_progressbar=False)\n",
        "    print('{} - {} - lower: {:.3f}'.format(\n",
        "        col, \n",
        "        -trials.best_trial['result']['loss'],\n",
        "        best['lower']/len(oof_pred),\n",
        "        # best['upper']/len(oof_pred)\n",
        "        ))\n",
        "    score.append(-trials.best_trial['result']['loss'])\n",
        "    lower.append(round(best['lower']/len(oof_pred), 2))\n",
        "# bbu3: 0.44169\n",
        "# bbu4: 0.45214\n",
        "print(np.mean(score))\n",
        "\n",
        "hyper2 = pd.DataFrame(dict(col = target_col, lower = lower, score2 = score))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col</th>\n",
              "      <th>lower</th>\n",
              "      <th>score2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>question_asker_intent_understanding</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.37807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>question_body_critical</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>question_conversational</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.52646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>question_expect_short_answer</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.30577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>question_fact_seeking</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>question_has_commonly_accepted_answer</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.43002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>question_interestingness_others</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.35939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>question_interestingness_self</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.52263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>question_multi_intent</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.61034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>question_not_really_a_question</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.13796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>question_opinion_seeking</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.48662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>question_type_choice</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.76763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>question_type_compare</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.54274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>question_type_consequence</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.29275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>question_type_definition</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.63611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>question_type_entity</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.60235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>question_type_instructions</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.78695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>question_type_procedure</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.35181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>question_type_reason_explanation</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.67592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>question_type_spelling</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.33313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>question_well_written</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.52272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>answer_helpful</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>answer_level_of_information</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.43197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>answer_plausible</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.16196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>answer_relevance</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>answer_satisfaction</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.33920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>answer_type_instructions</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.76717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>answer_type_procedure</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.27725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>answer_type_reason_explanation</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.68824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>answer_well_written</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.18539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      col  lower   score2\n",
              "0     question_asker_intent_understanding   0.07  0.37807\n",
              "1                  question_body_critical   0.00  0.63432\n",
              "2                 question_conversational   0.88  0.52646\n",
              "3            question_expect_short_answer   0.00  0.30577\n",
              "4                   question_fact_seeking   0.00  0.37506\n",
              "5   question_has_commonly_accepted_answer   0.00  0.43002\n",
              "6         question_interestingness_others   0.46  0.35939\n",
              "7           question_interestingness_self   0.62  0.52263\n",
              "8                   question_multi_intent   0.54  0.61034\n",
              "9          question_not_really_a_question   0.93  0.13796\n",
              "10               question_opinion_seeking   0.00  0.48662\n",
              "11                   question_type_choice   0.46  0.76763\n",
              "12                  question_type_compare   0.95  0.54274\n",
              "13              question_type_consequence   0.99  0.29275\n",
              "14               question_type_definition   0.93  0.63611\n",
              "15                   question_type_entity   0.88  0.60235\n",
              "16             question_type_instructions   0.28  0.78695\n",
              "17                question_type_procedure   0.08  0.35181\n",
              "18       question_type_reason_explanation   0.32  0.67592\n",
              "19                 question_type_spelling   1.00  0.33313\n",
              "20                  question_well_written   0.17  0.52272\n",
              "21                         answer_helpful   0.00  0.23759\n",
              "22            answer_level_of_information   0.00  0.43197\n",
              "23                       answer_plausible   0.05  0.16196\n",
              "24                       answer_relevance   0.00  0.19678\n",
              "25                    answer_satisfaction   0.00  0.33920\n",
              "26               answer_type_instructions   0.20  0.76717\n",
              "27                  answer_type_procedure   0.00  0.27725\n",
              "28         answer_type_reason_explanation   0.04  0.68824\n",
              "29                    answer_well_written   0.04  0.18539"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czO2o18alP1a",
        "colab_type": "text"
      },
      "source": [
        "### Use n-binning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTzolfJeWgXR",
        "colab_type": "code",
        "outputId": "67fa0dd0-f8df-4ec5-b638-d4985d26173e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# bbu3: 0.43042\n",
        "# bbu4: \n",
        "\n",
        "def f1_min(params, col):\n",
        "    tmp = oof_pred.copy()[col].values\n",
        "    paramlist = [params['p'+str(i)] for i in range(len(params))]\n",
        "    bins = np.percentile(tmp, paramlist)\n",
        "    tmp = np.digitize(tmp, np.sort(bins)) / len(bins)\n",
        "    score = spearmanr(train[col].values, tmp).correlation\n",
        "    return {'loss': -round(score, 5), 'status': STATUS_OK}\n",
        "\n",
        "def f2_min(params, col):\n",
        "    cutoff = {'p'+str(i): hp.randint('p'+str(i), 101) for i in range(params['num_bin'])}\n",
        "    f = partial(f1_min, col=col)\n",
        "    trials = Trials()\n",
        "    best = fmin(f, cutoff, tpe.suggest, 100, rstate=np.random.RandomState(0), trials=trials, \n",
        "                show_progressbar=False)\n",
        "    # print('{} - {}'.format(col, -trials.best_trial['result']['loss']))\n",
        "    score = -trials.best_trial['result']['loss']\n",
        "    return {'loss': -round(score, 5), 'status': STATUS_OK, 'cutoff': list(best.values())}\n",
        "\n",
        "score, cutoffs = [], []\n",
        "for col in target_col:\n",
        "    numbin = {'num_bin': hp.randint('num_bin', 19)+2}\n",
        "    f = partial(f2_min, col=col)\n",
        "    trials = Trials()\n",
        "    best = fmin(f, numbin, tpe.suggest, 10, rstate=np.random.RandomState(0), trials=trials, show_progressbar=False)\n",
        "    print('{} - {}'.format(col, -trials.best_trial['result']['loss']))\n",
        "    score.append(-trials.best_trial['result']['loss'])\n",
        "    cutoffs.append(trials.best_trial['result']['cutoff'])\n",
        "\n",
        "print(np.mean(score))\n",
        "hyper3 = pd.DataFrame(dict(col = target_col, cutoffs_pct = cutoffs, score3 = score))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question_asker_intent_understanding - 0.37851\n",
            "question_body_critical - 0.63356\n",
            "question_conversational - 0.5164\n",
            "question_expect_short_answer - 0.30806\n",
            "question_fact_seeking - 0.37662\n",
            "question_has_commonly_accepted_answer - 0.48123\n",
            "question_interestingness_others - 0.35821\n",
            "question_interestingness_self - 0.51695\n",
            "question_multi_intent - 0.60606\n",
            "question_not_really_a_question - 0.13406\n",
            "question_opinion_seeking - 0.48651\n",
            "question_type_choice - 0.76248\n",
            "question_type_compare - 0.53144\n",
            "question_type_consequence - 0.27764\n",
            "question_type_definition - 0.6253\n",
            "question_type_entity - 0.59428\n",
            "question_type_instructions - 0.79094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc-dHiXV8FjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question_asker_intent_understanding - 0.37912\n",
        "question_body_critical - 0.63471\n",
        "question_conversational - 0.47301\n",
        "question_expect_short_answer - 0.30801\n",
        "question_fact_seeking - 0.37662\n",
        "question_has_commonly_accepted_answer - 0.48017\n",
        "question_interestingness_others - 0.35821"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-09vXszbrtM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf4cfac9-de89-4772-95f9-8e2483ba0a44"
      },
      "source": [
        "# 0.44462\n",
        "hyper = hyper1.merge(hyper2, on='col').merge(hyper3, on='col')\n",
        "hyper.to_csv('drive/My Drive/GoogleQA/Data/hyper.csv', index=False)\n",
        "hyper['score'] = hyper[['score1', 'score2', 'score3']].max(axis=1)\n",
        "hyper['score'].mean()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col</th>\n",
              "      <th>lower</th>\n",
              "      <th>score1</th>\n",
              "      <th>cutoffs_pct</th>\n",
              "      <th>score2</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>question_asker_intent_understanding</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37869</td>\n",
              "      <td>[83, 43, 61, 72, 56, 91, 6, 4, 73, 71, 98, 96,...</td>\n",
              "      <td>0.38050</td>\n",
              "      <td>0.38050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>question_body_critical</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62999</td>\n",
              "      <td>[32, 55, 81, 86, 54, 79, 42, 71, 3, 84, 69, 41...</td>\n",
              "      <td>0.63132</td>\n",
              "      <td>0.63132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>question_conversational</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.50808</td>\n",
              "      <td>[75, 100, 92, 85, 74, 83]</td>\n",
              "      <td>0.48317</td>\n",
              "      <td>0.50808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>question_expect_short_answer</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.30653</td>\n",
              "      <td>[81, 14, 1, 83, 5, 91, 79, 68, 16, 58, 88, 56,...</td>\n",
              "      <td>0.30914</td>\n",
              "      <td>0.30914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>question_fact_seeking</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37795</td>\n",
              "      <td>[89, 11, 71, 15, 63, 14, 97, 35, 0, 16, 88, 55...</td>\n",
              "      <td>0.37937</td>\n",
              "      <td>0.37937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>question_has_commonly_accepted_answer</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.43624</td>\n",
              "      <td>[29, 7, 17]</td>\n",
              "      <td>0.48810</td>\n",
              "      <td>0.48810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>question_interestingness_others</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.34862</td>\n",
              "      <td>[85, 63, 3, 3, 97, 55, 63, 78, 49, 22, 36, 91,...</td>\n",
              "      <td>0.34866</td>\n",
              "      <td>0.34866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>question_interestingness_self</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50938</td>\n",
              "      <td>[80, 100, 93, 75, 83, 73, 95, 97, 53]</td>\n",
              "      <td>0.50707</td>\n",
              "      <td>0.50938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>question_multi_intent</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.58301</td>\n",
              "      <td>[81, 76, 61, 66, 92, 56, 40]</td>\n",
              "      <td>0.58103</td>\n",
              "      <td>0.58301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>question_not_really_a_question</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.10707</td>\n",
              "      <td>[1, 100, 88]</td>\n",
              "      <td>0.10102</td>\n",
              "      <td>0.10707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>question_opinion_seeking</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.48817</td>\n",
              "      <td>[82, 24, 93, 24, 12, 32, 13, 14, 70, 26, 16, 3...</td>\n",
              "      <td>0.49089</td>\n",
              "      <td>0.49089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>question_type_choice</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.75155</td>\n",
              "      <td>[70, 94, 82, 61, 50, 51, 54, 89, 49]</td>\n",
              "      <td>0.74865</td>\n",
              "      <td>0.75155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>question_type_compare</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.53939</td>\n",
              "      <td>[81, 70, 96, 74, 88, 88, 82]</td>\n",
              "      <td>0.41769</td>\n",
              "      <td>0.53939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>question_type_consequence</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.25704</td>\n",
              "      <td>[1, 100, 88]</td>\n",
              "      <td>0.23491</td>\n",
              "      <td>0.25704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>question_type_definition</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.63655</td>\n",
              "      <td>[4, 86, 2]</td>\n",
              "      <td>0.46234</td>\n",
              "      <td>0.63655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>question_type_entity</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.61179</td>\n",
              "      <td>[100, 88, 91]</td>\n",
              "      <td>0.60080</td>\n",
              "      <td>0.61179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>question_type_instructions</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.78876</td>\n",
              "      <td>[44, 100, 48, 34, 31, 67, 64, 98, 32, 100, 41,...</td>\n",
              "      <td>0.79420</td>\n",
              "      <td>0.79420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>question_type_procedure</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.35947</td>\n",
              "      <td>[86, 77, 5, 39, 51, 39, 40, 3, 81, 26, 99, 85,...</td>\n",
              "      <td>0.36130</td>\n",
              "      <td>0.36130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>question_type_reason_explanation</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.67579</td>\n",
              "      <td>[39, 26, 58, 14, 47, 5, 77, 98, 32, 42, 12, 93...</td>\n",
              "      <td>0.67618</td>\n",
              "      <td>0.67618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>question_type_spelling</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.16542</td>\n",
              "      <td>[97, 94, 87]</td>\n",
              "      <td>0.10659</td>\n",
              "      <td>0.16542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>question_well_written</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.52394</td>\n",
              "      <td>[77, 83, 44, 35, 82, 9, 38, 77, 99, 74, 29, 99...</td>\n",
              "      <td>0.52490</td>\n",
              "      <td>0.52490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>answer_helpful</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23555</td>\n",
              "      <td>[20, 4, 62, 89, 2, 65, 84, 83, 42, 22, 26, 29,...</td>\n",
              "      <td>0.23782</td>\n",
              "      <td>0.23782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>answer_level_of_information</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.41974</td>\n",
              "      <td>[56, 75, 12, 87, 51, 7, 10, 35, 54, 37, 98, 80...</td>\n",
              "      <td>0.42060</td>\n",
              "      <td>0.42060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>answer_plausible</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.16575</td>\n",
              "      <td>[74, 100, 66, 66, 75, 12, 1, 55, 88, 50, 63, 4...</td>\n",
              "      <td>0.16879</td>\n",
              "      <td>0.16879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>answer_relevance</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.18567</td>\n",
              "      <td>[12, 22, 8, 88, 43, 21, 23]</td>\n",
              "      <td>0.18898</td>\n",
              "      <td>0.18898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>answer_satisfaction</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.33193</td>\n",
              "      <td>[89, 66, 8, 63, 14, 60, 56, 64, 95, 10, 66, 99...</td>\n",
              "      <td>0.33306</td>\n",
              "      <td>0.33306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>answer_type_instructions</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.76775</td>\n",
              "      <td>[54, 34, 25, 70, 68, 25, 48]</td>\n",
              "      <td>0.76818</td>\n",
              "      <td>0.76818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>answer_type_procedure</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.28892</td>\n",
              "      <td>[94, 36, 10, 88, 33, 35]</td>\n",
              "      <td>0.29221</td>\n",
              "      <td>0.29221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>answer_type_reason_explanation</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.68453</td>\n",
              "      <td>[37, 8, 40, 15, 44, 27, 32, 40, 24, 21, 18, 44...</td>\n",
              "      <td>0.68556</td>\n",
              "      <td>0.68556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>answer_well_written</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18758</td>\n",
              "      <td>[74, 33, 75, 74, 53, 25, 73, 77, 31, 6, 81, 93...</td>\n",
              "      <td>0.18950</td>\n",
              "      <td>0.18950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      col  lower  ...   score2    score\n",
              "0     question_asker_intent_understanding   0.00  ...  0.38050  0.38050\n",
              "1                  question_body_critical   0.00  ...  0.63132  0.63132\n",
              "2                 question_conversational   0.91  ...  0.48317  0.50808\n",
              "3            question_expect_short_answer   0.00  ...  0.30914  0.30914\n",
              "4                   question_fact_seeking   0.00  ...  0.37937  0.37937\n",
              "5   question_has_commonly_accepted_answer   0.00  ...  0.48810  0.48810\n",
              "6         question_interestingness_others   0.24  ...  0.34866  0.34866\n",
              "7           question_interestingness_self   0.53  ...  0.50707  0.50938\n",
              "8                   question_multi_intent   0.40  ...  0.58103  0.58301\n",
              "9          question_not_really_a_question   0.88  ...  0.10102  0.10707\n",
              "10               question_opinion_seeking   0.04  ...  0.49089  0.49089\n",
              "11                   question_type_choice   0.48  ...  0.74865  0.75155\n",
              "12                  question_type_compare   0.95  ...  0.41769  0.53939\n",
              "13              question_type_consequence   0.99  ...  0.23491  0.25704\n",
              "14               question_type_definition   0.93  ...  0.46234  0.63655\n",
              "15                   question_type_entity   0.88  ...  0.60080  0.61179\n",
              "16             question_type_instructions   0.26  ...  0.79420  0.79420\n",
              "17                question_type_procedure   0.07  ...  0.36130  0.36130\n",
              "18       question_type_reason_explanation   0.20  ...  0.67618  0.67618\n",
              "19                 question_type_spelling   1.00  ...  0.10659  0.16542\n",
              "20                  question_well_written   0.09  ...  0.52490  0.52490\n",
              "21                         answer_helpful   0.00  ...  0.23782  0.23782\n",
              "22            answer_level_of_information   0.00  ...  0.42060  0.42060\n",
              "23                       answer_plausible   0.00  ...  0.16879  0.16879\n",
              "24                       answer_relevance   0.00  ...  0.18898  0.18898\n",
              "25                    answer_satisfaction   0.00  ...  0.33306  0.33306\n",
              "26               answer_type_instructions   0.24  ...  0.76818  0.76818\n",
              "27                  answer_type_procedure   0.04  ...  0.29221  0.29221\n",
              "28         answer_type_reason_explanation   0.08  ...  0.68556  0.68556\n",
              "29                    answer_well_written   0.17  ...  0.18950  0.18950\n",
              "\n",
              "[30 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4pu4zbKpBAW",
        "colab_type": "text"
      },
      "source": [
        "## test prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2J1yS8HpCrx",
        "colab_type": "code",
        "outputId": "33503632-4bd6-428d-d6e5-696f1e5f55a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "test_pred = pd.read_csv('drive/My Drive/GoogleQA/Data/test_oof_pred.csv')\n",
        "hyper = pd.read_csv('drive/My Drive/GoogleQA/Data/hyper.csv')\n",
        "pred = test_pred[target_col].copy().values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col</th>\n",
              "      <th>pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>question_conversational</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>question_interestingness_others</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>question_interestingness_self</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>question_multi_intent</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>question_not_really_a_question</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>question_opinion_seeking</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>question_type_choice</td>\n",
              "      <td>0.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>question_type_compare</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>question_type_consequence</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>question_type_definition</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>question_type_entity</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>question_type_instructions</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>question_type_procedure</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>question_type_reason_explanation</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>question_type_spelling</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>question_well_written</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>answer_type_instructions</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>answer_type_procedure</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>answer_type_reason_explanation</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>answer_well_written</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 col   pct\n",
              "0            question_conversational  0.91\n",
              "1    question_interestingness_others  0.24\n",
              "2      question_interestingness_self  0.53\n",
              "3              question_multi_intent  0.40\n",
              "4     question_not_really_a_question  0.88\n",
              "5           question_opinion_seeking  0.04\n",
              "6               question_type_choice  0.48\n",
              "7              question_type_compare  0.95\n",
              "8          question_type_consequence  0.99\n",
              "9           question_type_definition  0.93\n",
              "10              question_type_entity  0.88\n",
              "11        question_type_instructions  0.26\n",
              "12           question_type_procedure  0.07\n",
              "13  question_type_reason_explanation  0.20\n",
              "14            question_type_spelling  1.00\n",
              "15             question_well_written  0.09\n",
              "16          answer_type_instructions  0.24\n",
              "17             answer_type_procedure  0.04\n",
              "18    answer_type_reason_explanation  0.08\n",
              "19               answer_well_written  0.17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRYN8QsepVkN",
        "colab_type": "code",
        "outputId": "235bd16c-0e19-4113-acf0-7fafa68338a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "for col in [x for x in target_col if x not in hyper.col.tolist()]:\n",
        "    pred[:, target_col.index(col)] = (pred[:, target_col.index(col)]//(1/90))/90\n",
        "for col in hyper.col.tolist():\n",
        "    if hyper.loc[hyper.col==col, 'pct'].values == 1:\n",
        "        pct = hyper.loc[hyper.col==col, 'pct'] - 0.01\n",
        "    else:\n",
        "        pct = hyper.loc[hyper.col==col, 'pct']\n",
        "    changerow = int(len(test) * pct)\n",
        "    rowidx = pred[:, target_col.index(col)].argsort()[:changerow]\n",
        "    pred[rowidx, target_col.index(col)] = 0\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19    0.17\n",
              "Name: pct, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kTeS0BQrJUL",
        "colab_type": "code",
        "outputId": "7c6c14af-90f2-4683-afc7-6652d18a4c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "for i in range(pred.shape[1]):\n",
        "    print(i, len(np.unique(pred[:, i])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 24\n",
            "1 53\n",
            "2 44\n",
            "3 58\n",
            "4 49\n",
            "5 54\n",
            "6 363\n",
            "7 225\n",
            "8 287\n",
            "9 59\n",
            "10 458\n",
            "11 249\n",
            "12 25\n",
            "13 6\n",
            "14 35\n",
            "15 59\n",
            "16 354\n",
            "17 444\n",
            "18 382\n",
            "19 6\n",
            "20 435\n",
            "21 16\n",
            "22 25\n",
            "23 8\n",
            "24 9\n",
            "25 24\n",
            "26 363\n",
            "27 458\n",
            "28 439\n",
            "29 397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRMV2dmrNV4x",
        "colab_type": "text"
      },
      "source": [
        "## USE Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOvLGUbfNX9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# train['sentence'] = train['question'] + ' ' + train['answer']\n",
        "embed1 = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
        "# embed2 = hub.load('https://tfhub.dev/google/nnlm-en-dim128/2')\n",
        "\n",
        "def UniversalEmbedding(x):\n",
        "    return embed1(tf.squeeze(tf.cast(x, tf.string)))\n",
        "\n",
        "# def NNLMEmbedding(x):\n",
        "#     return embed2(tf.squeeze(tf.cast(x, tf.string)))\n",
        "\n",
        "def use_model():\n",
        "    \n",
        "    q = keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "    qb = keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "    a = keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "\n",
        "    def hidden_layer(input_layer):\n",
        "        x = keras.layers.Lambda(UniversalEmbedding, output_shape=(512, ))(input_layer)\n",
        "        # embed2 = keras.layers.Lambda(NNLMEmbedding, output_shape=(128, ))(input_layer)\n",
        "        # embed = keras.layers.concatenate([embed1, embed2])\n",
        "        x = keras.layers.Dropout(0.2)(x)\n",
        "        x = keras.backend.expand_dims(x, axis=1)\n",
        "        # x = keras.layers.Bidirectional(keras.layers.CuDNNLSTM(128, return_sequences=True))(x)\n",
        "        # x = keras.layers.Bidirectional(keras.layers.CuDNNLSTM(128, return_sequences=True))(x)\n",
        "        # GP = keras.layers.GlobalMaxPooling1D()(x)\n",
        "        # GP = keras.layers.Dropout(0.2)(GP)\n",
        "        # AP = keras.layers.GlobalAveragePooling1D()(x)\n",
        "        # AP = keras.layers.Dropout(0.2)(AP)\n",
        "        # hidden = keras.layers.concatenate([GP, AP])\n",
        "        # hidden = keras.layers.add([hidden, keras.layers.Dense(512, activation='relu')(hidden)])\n",
        "        # hidden = keras.layers.add([hidden, keras.layers.Dense(512, activation='relu')(hidden)])\n",
        "\n",
        "        x1 = keras.layers.Bidirectional(keras.layers.CuDNNLSTM(256, return_sequences=True))(x)\n",
        "        x2 = keras.layers.Bidirectional(keras.layers.CuDNNGRU(128, return_sequences=True))(x1)\n",
        "        max_pool1 = keras.layers.GlobalMaxPooling1D()(x1)\n",
        "        max_pool2 = keras.layers.GlobalMaxPooling1D()(x2)\n",
        "        hidden = keras.layers.concatenate([max_pool1, max_pool2])\n",
        "        return hidden\n",
        "\n",
        "    q_embed, qb_embed, a_embed = hidden_layer(q), hidden_layer(qb), hidden_layer(a)\n",
        "    all_embed = keras.layers.concatenate([q_embed, qb_embed, a_embed])\n",
        "    dense = keras.layers.Dense(256, activation='relu')(all_embed)\n",
        "    pred = keras.layers.Dense(30, activation='sigmoid')(dense)\n",
        "    model = keras.Model(inputs=[q, qb, a], outputs=pred)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=5e-3))\n",
        "    # del embed\n",
        "    # gc.collect()\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTIxpMnFNhju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "idx = [x for x in kf.split(train, groups=train.question_body)]\n",
        "def compute_spearmanr(trues, preds):\n",
        "    rhos = []\n",
        "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
        "        rhos.append(spearmanr(col_trues, col_pred).correlation)\n",
        "    return np.mean(rhos)\n",
        "\n",
        "class IntervalEval(keras.callbacks.Callback):\n",
        "    def __init__(self, val_data, label):\n",
        "        super(keras.callbacks.Callback, self).__init__()\n",
        "        self.val_data = val_data\n",
        "        self.score = 0\n",
        "        self.maxscore = 0\n",
        "        self.label = label\n",
        "        self.patience = 3\n",
        "        self.count = 0\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # if epoch == 3:\n",
        "        val_pred = self.model.predict(self.val_data, batch_size=16, verbose=1)\n",
        "        score = compute_spearmanr(self.label, val_pred)\n",
        "        print('Spearman - {:.5f}'.format(score))\n",
        "        if self.maxscore>=0.3:\n",
        "            self.patience=2\n",
        "        if (score < self.score):\n",
        "            self.score = score\n",
        "            self.count+=1\n",
        "            if self.count==self.patience:\n",
        "                self.model.stop_training=True\n",
        "        elif score > self.maxscore:\n",
        "            self.score = score\n",
        "            self.maxscore = score\n",
        "            self.count = 0\n",
        "            if self.maxscore > 0.3:\n",
        "                self.model.save('drive/My Drive/GoogleQA/Models/{:}/use-model-{:}.h5'.format(save_model, i))\n",
        "        else:\n",
        "            self.score = score\n",
        "            self.count = 0\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bd--Dd_QUof",
        "colab_type": "code",
        "outputId": "4a135471-867b-4a2e-ba23-c5fe112ac9d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "    keras.backend.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    for i, (tr_idx, val_idx) in enumerate(idx, 1):\n",
        "        print('\\nFold - {:}\\n'.format(i))\n",
        "        tr, val = train.loc[tr_idx], train.loc[val_idx]\n",
        "        tr_x = [tr['question_title'], tr['question_body'], tr['answer']]\n",
        "        val_x = [val['question_title'], val['question_body'], val['answer']]\n",
        "        ieval = IntervalEval(val_data=val_x, label=val[target_col].values)\n",
        "        model = use_model()\n",
        "        history = model.fit(\n",
        "            tr_x,\n",
        "            tr[target_col],\n",
        "            epochs=100, \n",
        "            batch_size=16,\n",
        "            callbacks=[ieval])\n",
        "        del model, tr, val, tr_x, val_x\n",
        "        gc.collect()\n",
        "\n",
        "# with tf.Session() as session:\n",
        "#     keras.backend.set_session(session)\n",
        "#     session.run(tf.global_variables_initializer())  \n",
        "#     session.run(tf.tables_initializer())\n",
        "#     model.load_weights('use-model-1.h5')\n",
        "#     preds = model.predict(val['sentence'], batch_size=16, verbose=1)\n",
        "#     score=compute_spearmanr(val[target_col].values, preds)\n",
        "#     print('Spearman - {:.5f}'.format(score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold - 1\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 33s 27ms/sample\n",
            "Spearman - 0.35849\n",
            "4863/4863 [==============================] - 170s 35ms/sample - loss: 0.3946\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36453\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3720\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37807\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3628\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37832\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3549\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37996\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3462\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37266\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3358\n",
            "Epoch 7/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36546\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3244\n",
            "\n",
            "Fold - 2\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 34s 28ms/sample\n",
            "Spearman - 0.33703\n",
            "4863/4863 [==============================] - 156s 32ms/sample - loss: 0.3924\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.34534\n",
            "4863/4863 [==============================] - 88s 18ms/sample - loss: 0.3710\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36068\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3621\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36306\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3539\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36120\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3444\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35571\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3338\n",
            "\n",
            "Fold - 3\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 34s 28ms/sample\n",
            "Spearman - 0.34580\n",
            "4863/4863 [==============================] - 160s 33ms/sample - loss: 0.3934\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36574\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3713\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37321\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3624\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36790\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3541\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 15s 13ms/sample\n",
            "Spearman - 0.37437\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3454\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35966\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3339\n",
            "Epoch 7/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35308\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3227\n",
            "\n",
            "Fold - 4\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 35s 29ms/sample\n",
            "Spearman - 0.34625\n",
            "4863/4863 [==============================] - 160s 33ms/sample - loss: 0.3937\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35942\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3718\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36250\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3624\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36419\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3542\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36604\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3455\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 14ms/sample\n",
            "Spearman - 0.35845\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3351\n",
            "Epoch 7/100\n",
            "1216/1216 [==============================] - 16s 14ms/sample\n",
            "Spearman - 0.36201\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3232\n",
            "Epoch 8/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35785\n",
            "4863/4863 [==============================] - 85s 17ms/sample - loss: 0.3119\n",
            "Epoch 9/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35012\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3011\n",
            "\n",
            "Fold - 5\n",
            "\n",
            "Train on 4864 samples\n",
            "Epoch 1/100\n",
            "1215/1215 [==============================] - 37s 30ms/sample\n",
            "Spearman - 0.34068\n",
            "4864/4864 [==============================] - 168s 34ms/sample - loss: 0.3943\n",
            "Epoch 2/100\n",
            "1215/1215 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35529\n",
            "4864/4864 [==============================] - 86s 18ms/sample - loss: 0.3726\n",
            "Epoch 3/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35790\n",
            "4864/4864 [==============================] - 86s 18ms/sample - loss: 0.3637\n",
            "Epoch 4/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35886\n",
            "4864/4864 [==============================] - 86s 18ms/sample - loss: 0.3551\n",
            "Epoch 5/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36241\n",
            "4864/4864 [==============================] - 87s 18ms/sample - loss: 0.3468\n",
            "Epoch 6/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35775\n",
            "4864/4864 [==============================] - 85s 17ms/sample - loss: 0.3355\n",
            "Epoch 7/100\n",
            "1215/1215 [==============================] - 16s 14ms/sample\n",
            "Spearman - 0.34976\n",
            "4864/4864 [==============================] - 85s 17ms/sample - loss: 0.3240\n",
            "\n",
            "Fold - 6\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 37s 30ms/sample\n",
            "Spearman - 0.33484\n",
            "4863/4863 [==============================] - 169s 35ms/sample - loss: 0.3942\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36367\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3720\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36417\n",
            "4863/4863 [==============================] - 87s 18ms/sample - loss: 0.3626\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36823\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3540\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36329\n",
            "4863/4863 [==============================] - 85s 17ms/sample - loss: 0.3453\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35710\n",
            "4863/4863 [==============================] - 82s 17ms/sample - loss: 0.3342\n",
            "\n",
            "Fold - 7\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 36s 30ms/sample\n",
            "Spearman - 0.34222\n",
            "4863/4863 [==============================] - 168s 35ms/sample - loss: 0.3936\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35259\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3722\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.34803\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3635\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35987\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3550\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 15s 13ms/sample\n",
            "Spearman - 0.36029\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3457\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35276\n",
            "4863/4863 [==============================] - 83s 17ms/sample - loss: 0.3352\n",
            "Epoch 7/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.34791\n",
            "4863/4863 [==============================] - 83s 17ms/sample - loss: 0.3231\n",
            "\n",
            "Fold - 8\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 37s 30ms/sample\n",
            "Spearman - 0.33639\n",
            "4863/4863 [==============================] - 172s 35ms/sample - loss: 0.3933\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 15s 13ms/sample\n",
            "Spearman - 0.36531\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3722\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 15s 13ms/sample\n",
            "Spearman - 0.36391\n",
            "4863/4863 [==============================] - 83s 17ms/sample - loss: 0.3632\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37153\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3548\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36293\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3456\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35556\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3350\n",
            "\n",
            "Fold - 9\n",
            "\n",
            "Train on 4863 samples\n",
            "Epoch 1/100\n",
            "1216/1216 [==============================] - 38s 31ms/sample\n",
            "Spearman - 0.33901\n",
            "4863/4863 [==============================] - 179s 37ms/sample - loss: 0.3935\n",
            "Epoch 2/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35072\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3710\n",
            "Epoch 3/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36947\n",
            "4863/4863 [==============================] - 86s 18ms/sample - loss: 0.3626\n",
            "Epoch 4/100\n",
            "1216/1216 [==============================] - 16s 14ms/sample\n",
            "Spearman - 0.36432\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3540\n",
            "Epoch 5/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.36742\n",
            "4863/4863 [==============================] - 85s 17ms/sample - loss: 0.3452\n",
            "Epoch 6/100\n",
            "1216/1216 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35627\n",
            "4863/4863 [==============================] - 85s 18ms/sample - loss: 0.3352\n",
            "Epoch 7/100\n",
            "1216/1216 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.35086\n",
            "4863/4863 [==============================] - 84s 17ms/sample - loss: 0.3234\n",
            "\n",
            "Fold - 10\n",
            "\n",
            "Train on 4864 samples\n",
            "Epoch 1/100\n",
            "1215/1215 [==============================] - 39s 32ms/sample\n",
            "Spearman - 0.35438\n",
            "4864/4864 [==============================] - 184s 38ms/sample - loss: 0.3930\n",
            "Epoch 2/100\n",
            "1215/1215 [==============================] - 16s 14ms/sample\n",
            "Spearman - 0.37118\n",
            "4864/4864 [==============================] - 87s 18ms/sample - loss: 0.3713\n",
            "Epoch 3/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36850\n",
            "4864/4864 [==============================] - 86s 18ms/sample - loss: 0.3621\n",
            "Epoch 4/100\n",
            "1215/1215 [==============================] - 16s 13ms/sample\n",
            "Spearman - 0.37393\n",
            "4864/4864 [==============================] - 91s 19ms/sample - loss: 0.3541\n",
            "Epoch 5/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.37396\n",
            "4864/4864 [==============================] - 89s 18ms/sample - loss: 0.3447\n",
            "Epoch 6/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.36964\n",
            "4864/4864 [==============================] - 87s 18ms/sample - loss: 0.3342\n",
            "Epoch 7/100\n",
            "1215/1215 [==============================] - 17s 14ms/sample\n",
            "Spearman - 0.35713\n",
            "4864/4864 [==============================] - 87s 18ms/sample - loss: 0.3228\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}