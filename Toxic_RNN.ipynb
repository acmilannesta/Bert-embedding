{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic_RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acmilannesta/Bert-embedding/blob/master/Toxic_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKhYbkkRwQ9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktU5oajByf3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c jigsaw-unintended-bias-in-toxicity-classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsECSOvhuCQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFfFwAv9sh2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9fc9c4e-468f-46d2-c256-80bfc60107ca"
      },
      "source": [
        "import pickle\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, Dropout, add, concatenate, CuDNNLSTM, CuDNNGRU\n",
        "from keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMyGXNGGs6BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 220\n",
        "BATCH_SIZE = 512\n",
        "NUM_EPOCHS = 4\n",
        "LSTM_UNITS = 128\n",
        "DENSE_HIDDEN_UNITS = 512\n",
        "NUM_MODELS = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaKpWSBLwcW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.load('drive/My Drive/Data/X_train.npy')\n",
        "X_test = np.load('drive/My Drive/Data/X_test.npy')\n",
        "embedding_matrix = np.load('drive/My Drive/Data/crawl+glove.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9p6gVMovm2I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "229f6f49-9193-4ca0-ee16-58a601ec65dd"
      },
      "source": [
        "train = pd.read_csv('train.csv.zip')\n",
        "identity_columns = [\n",
        "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
        "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
        "# Overall\n",
        "weights = np.ones((len(train),)) / 4\n",
        "# Subgroup\n",
        "weights += (train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) / 4\n",
        "# Background Positive, Subgroup Negative\n",
        "weights += (( (train['target'].values>=0.5).astype(np.int) +\n",
        "   (train[identity_columns].fillna(0).values<0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(np.int) / 4\n",
        "# Background Negative, Subgroup Positive\n",
        "weights += (( (train['target'].values<0.5).astype(np.int) +\n",
        "   (train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(np.int) / 4\n",
        "loss_weight = 1.0 / weights.mean()\n",
        "y_train = np.vstack([(train['target'].values>=0.5).astype(np.int), weights]).T\n",
        "# y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']].values\n",
        "del train\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6tXPOG_z0fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(K.reshape(y_true[:,0],(-1,1)), y_pred) * y_true[:,1]\n",
        "def build_model(embedding_matrix):\n",
        "\n",
        "    words = Input(shape=(MAX_LEN,))\n",
        "    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n",
        "    x = SpatialDropout1D(0.3)(x)\n",
        "    x = Bidirectional(CuDNNGRU(LSTM_UNITS, return_sequences=True))(x)\n",
        "    x = Bidirectional(CuDNNGRU(LSTM_UNITS, return_sequences=True))(x)\n",
        "\n",
        "    hidden = concatenate([GlobalMaxPooling1D()(x), GlobalAveragePooling1D()(x), ])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
        "    result = Dense(1, activation='sigmoid')(hidden)\n",
        "#     aux_result = Dense(num_aux_targets, activation='sigmoid')(hidden)\n",
        "\n",
        "    model = Model(inputs=words, outputs=result)\n",
        "    model.compile(loss=custom_loss, \n",
        "#                   loss_weights=[loss_weight, 1.0], \n",
        "                  optimizer='adam')\n",
        "\n",
        "    return model\n",
        "def run_model(X_train, y_train, embedding_matrix):\n",
        "    checkpoint_predictions = []\n",
        "    weights = []\n",
        "    for model_idx in range(NUM_MODELS):\n",
        "        model = build_model(embedding_matrix)\n",
        "        for global_epoch in range(NUM_EPOCHS):\n",
        "            model.fit(\n",
        "                X_train, y_train,\n",
        "                batch_size=BATCH_SIZE, epochs=1, verbose=1,\n",
        "                callbacks=[LearningRateScheduler(lambda epoch: 1e-3 * (0.6 ** global_epoch))]\n",
        "            )\n",
        "#             with open('temporary.pickle', mode='rb') as f:\n",
        "#                 X_test = pickle.load(f)  # use temporary file to reduce memory\n",
        "            checkpoint_predictions.append(model.predict(X_test, batch_size=2048)[0].flatten())\n",
        "#             del X_test\n",
        "#             gc.collect()\n",
        "            weights.append(2 ** global_epoch)\n",
        "        del model\n",
        "        gc.collect()\n",
        "\n",
        "    preds = np.average(checkpoint_predictions, weights=weights, axis=0)\n",
        "    return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMQ2h-Xe0TRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "796aa28c-7076-4dbe-cb18-69d2abfdfc63"
      },
      "source": [
        "test_pred = run_model(X_train, y_train, embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Epoch 1/1\n",
            " 131584/1804874 [=>............................] - ETA: 15:51 - loss: 0.0889"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}