{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acmilannesta/Bert-embedding/blob/master/Bert_adultreadmission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ItDxs5xGRfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0TXgKiFFVyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de2c14bf-3934-40ca-c66e-978a3b6c232b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgw-2XW8Geus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras_bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "306WTFXmGPA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import choice\n",
        "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
        "import re, os, gc\n",
        "import codecs\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJhMtLYVGl0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 300\n",
        "config_path = '/content/drive/My Drive/biobert_pretrain_output_all_notes_150000/bert_config.json' #'uncased_L-12_H-768_A-12/bert_config.json'\n",
        "checkpoint_path = '/content/drive/My Drive/biobert_pretrain_output_all_notes_150000/model.ckpt' #'uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
        "dict_path = '/content/drive/My Drive/biobert_pretrain_output_all_notes_150000/vocab.txt' #'uncased_L-12_H-768_A-12/vocab.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HC_n547GuYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict = {}\n",
        "\n",
        "with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r973L4toG4s3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class OurTokenizer(Tokenizer):\n",
        "#     def _tokenize(self, text):\n",
        "#         R = []\n",
        "#         for c in text:\n",
        "#             if c in self._token_dict:\n",
        "#                 R.append(c)\n",
        "#             # elif self._is_space(c):\n",
        "#             #     R.append('[unused1]')\n",
        "#             else:\n",
        "#                 R.append('[UNK]')\n",
        "#         return R\n",
        "\n",
        "tokenizer = Tokenizer(token_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQK47tDfHL-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('drive/My Drive/Adult readmission/Combined_vars_04092019_notes.csv')\n",
        "data = data[['opnote_1', 'CODE_REHOSP']].dropna()\n",
        "data.CODE_REHOSP = np.where(data.CODE_REHOSP==2, 0, 1)\n",
        "random_order = list(range(len(data)))\n",
        "np.random.shuffle(random_order)\n",
        "train_data = [data.iloc[j] for i, j in enumerate(random_order) if i % 5 != 0]\n",
        "valid_data = [data.iloc[j] for i, j in enumerate(random_order) if i % 5 == 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl-tLqJGHXij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_padding(X, padding=0):\n",
        "    L = [len(x) for x in X]\n",
        "    ML = max(L)\n",
        "    return np.array([\n",
        "        np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x for x in X\n",
        "    ])\n",
        "\n",
        "class data_generator:\n",
        "    def __init__(self, data, batch_size=8):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.steps = len(self.data) // self.batch_size\n",
        "        if len(self.data) % self.batch_size != 0:\n",
        "            self.steps += 1\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "    def __iter__(self):\n",
        "        while True:\n",
        "          idxs = list(range(len(self.data)))\n",
        "          np.random.shuffle(idxs)\n",
        "          X1, X2, Y = [], [], []\n",
        "          for i in idxs:\n",
        "            d = self.data[i]\n",
        "            text = d[0][:maxlen]\n",
        "            x1, x2 = tokenizer.encode(first=text)\n",
        "            y = d[1]\n",
        "            X1.append(x1)\n",
        "            X2.append(x2)\n",
        "            Y.append([y])\n",
        "            if len(X1) == self.batch_size or i == idxs[-1]:\n",
        "                X1 = seq_padding(X1)\n",
        "                X2 = seq_padding(X2)\n",
        "                Y = seq_padding(Y)\n",
        "                yield [X1, X2], Y\n",
        "                [X1, X2, Y] = [], [], []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fnY5nGsHgHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path)\n",
        "for l in bert_model.layers:\n",
        "    l.trainable = True\n",
        "\n",
        "x1_in = Input(shape=(None,))\n",
        "x2_in = Input(shape=(None,))\n",
        "\n",
        "x = bert_model([x1_in, x2_in])\n",
        "x = Lambda(lambda x: x[:, 0])(x)\n",
        "p = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model([x1_in, x2_in], p)\n",
        "def auroc(y_true, y_pred):\n",
        "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(1e-5),\n",
        "    metrics=['acc']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31l7HU8ZHsAe",
        "colab_type": "code",
        "outputId": "78841378-d687-4a44-d5ec-b019504b0564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "train_D = data_generator(train_data)\n",
        "valid_D = data_generator(valid_data)\n",
        "model.fit_generator(\n",
        "    train_D.__iter__(),\n",
        "    steps_per_epoch=len(train_D),\n",
        "    epochs=2,\n",
        "    validation_data=valid_D.__iter__(),\n",
        "    validation_steps=len(valid_D)\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "147/147 [==============================] - 60s 410ms/step - loss: 0.5956 - acc: 0.7006 - val_loss: 0.6227 - val_acc: 0.7109\n",
            "Epoch 2/2\n",
            "147/147 [==============================] - 43s 293ms/step - loss: 0.5658 - acc: 0.7031 - val_loss: 0.6286 - val_acc: 0.7075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7390bd55c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2frFKaglPXeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1, X2, Y = [], [], []\n",
        "for i in range(len(valid_data)):\n",
        "  d = valid_data[i]\n",
        "  text = d[0][:maxlen]\n",
        "  x1, x2 = tokenizer.encode(first=text)\n",
        "  y = d[1]\n",
        "  X1.append(x1)\n",
        "  X2.append(x2)\n",
        "  Y.append([y])\n",
        "X1 = seq_padding(X1)\n",
        "X2 = seq_padding(X2)\n",
        "Y = seq_padding(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn5G__2CL2Mz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c012f014-79a7-4eec-da99-c7091e4967c7"
      },
      "source": [
        "pred = model.predict([X1, X2])\n",
        "print(roc_auc_score(Y, pred))\n",
        "Y.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(294, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}