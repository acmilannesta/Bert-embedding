{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoogleQA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acmilannesta/Bert-embedding/blob/master/GoogleQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D82bieSpLcuc",
        "colab_type": "code",
        "outputId": "410629fc-377a-4c13-a047-420847a4863e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Feb  4 00:12:16 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JErzYVOxLtWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nlp aug\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBrwK8dwLyw8",
        "colab_type": "code",
        "outputId": "8d954dad-7716-4460-b0e7-7d9dbf707311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaDm4NWvLp_J",
        "colab_type": "code",
        "outputId": "7a940eb1-c9ae-4009-fe48-c05ca941cb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import sys\n",
        "sys.path.extend(['/content/drive/My Drive/GoogleQA'])\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, gc, codecs\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GroupKFold, KFold, RepeatedKFold\n",
        "from scipy.stats import spearmanr\n",
        "from tqdm import tqdm\n",
        "import tensorflow_hub as hub\n",
        "from warmup_v2 import AdamWarmup, calc_train_steps\n",
        "tf.get_logger().setLevel('ERROR') \n",
        "from transformers import AlbertTokenizer, TFAlbertModel\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4yFl6cbgX6I",
        "colab_type": "text"
      },
      "source": [
        "##Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xGojs4dL6S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = 'drive/My Drive/GoogleQA/Data/'\n",
        "train = pd.read_csv(data_path+'train.csv')\n",
        "test = pd.read_csv(data_path+'test.csv')\n",
        "target_col = train.columns.tolist()[11:42]\n",
        "q_col, a_col = target_col[:21], target_col[21:]\n",
        "\n",
        "\n",
        "# Label encoding category and host\n",
        "class MyLabelEncoder(object):\n",
        "    \"\"\"safely handle unknown label\"\"\"\n",
        "    def __init__(self):\n",
        "        self.mapper = {}\n",
        "    def fit(self, X):\n",
        "        uniq_X = np.unique(X)\n",
        "        # reserve 0 for unknown\n",
        "        self.mapper = dict(zip(uniq_X, range(1, len(uniq_X) + 1)))\n",
        "        return self\n",
        "    def fit_transform(self, X):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "    def _map(self, x):\n",
        "        return self.mapper.get(x, 0)\n",
        "    def transform(self, X):\n",
        "        return list(map(self._map, X))\n",
        "\n",
        "category_encoder = MyLabelEncoder().fit(train['category'])\n",
        "train['category'] = category_encoder.transform(train['category'])\n",
        "test['category'] = category_encoder.transform(test['category'])\n",
        "host_encoder = MyLabelEncoder().fit(train['host'])\n",
        "train['host'] = host_encoder.transform(train['host'])\n",
        "test['host'] = host_encoder.transform(test['host'])\n",
        "\n",
        "# average question targets within the same questions\n",
        "def q_avg(data_df):\n",
        "    q_col_med = data_df.groupby(['question_title'], as_index=False)[q_col].mean()\n",
        "    return data_df.drop(target_col, 1).merge(q_col_med, how='left', on='question_title').drop_duplicates('question_title').reset_index(drop=True)\n",
        "\n",
        "# assign class weights\n",
        "def label_wt(data_df, cols, wt1=2, wt2=1.5, wt3=1):\n",
        "    for col in cols:\n",
        "        wt = data_df[col].value_counts(normalize=True).rename(col+'_wt').to_frame()\n",
        "        wt[col+'_wt'] = np.where(wt[col+'_wt']<=0.01, wt1, np.where(wt[col+'_wt']<=0.05, wt2, wt3))\n",
        "        data_df = data_df.merge(wt, 'left', left_on=col, right_on=wt.index)\n",
        "    return data_df\n",
        "\n",
        "# train, train_q, train_a = label_wt(train, target_col), label_wt(train_q, q_col), label_wt(train_a, a_col)\n",
        "col_wt, q_col_wt, a_col_wt = [x+'_wt' for x in target_col], [x+'_wt' for x in q_col], [x+'_wt' for x in a_col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7QNQl1wDJbi",
        "colab_type": "text"
      },
      "source": [
        "## Parameter setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPkHK5JvMJpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAXLEN = 512 \n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 4\n",
        "NUM_CLASSES = 30\n",
        "NUM_AUX = 6\n",
        "LR = 5e-5\n",
        "MIN_LR = 0\n",
        "\n",
        "model_path = 'drive/My Drive/GoogleQA/Albert'\n",
        "save_path = 'Albert'\n",
        "save_model = 'Albert' \n",
        "if save_path not in os.listdir('drive/My Drive/GoogleQA/Models'):\n",
        "    os.system(f'mkdir drive/My\\ Drive/GoogleQA/Models/{save_path}') \n",
        "\n",
        "CASED = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWJBpOFN7FCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _trim_input(title, question, answer, max_sequence_length=MAXLEN,\n",
        "                t_max_len=15, q_max_len=245, a_max_len=248):\n",
        "    t_len = len(title)\n",
        "    q_len = len(question)\n",
        "    a_len = len(answer)\n",
        "    if (t_len + q_len + a_len +6) > max_sequence_length:\n",
        "        if t_max_len > t_len:\n",
        "            t_new_len = t_len\n",
        "            a_max_len = a_max_len + np.floor((t_max_len - t_len) / 2)\n",
        "            q_max_len = q_max_len + np.ceil((t_max_len - t_len) / 2)\n",
        "        else:\n",
        "            t_new_len = t_max_len\n",
        "        if a_max_len > a_len:\n",
        "            a_new_len = a_len\n",
        "            q_new_len = q_max_len + (a_max_len - a_len)\n",
        "        elif q_max_len > q_len:\n",
        "            a_new_len = a_max_len + (q_max_len - q_len)\n",
        "            q_new_len = q_len\n",
        "        else:\n",
        "            a_new_len = a_max_len\n",
        "            q_new_len = q_max_len\n",
        "        if t_new_len + a_new_len + q_new_len +6 != max_sequence_length:\n",
        "            raise ValueError(\"New sequence length should be %d, but is %d\"\n",
        "                    % (max_sequence_length, (t_new_len + a_new_len + q_new_len +6)))\n",
        "        head_t_new_len = int(0.25 * t_new_len)\n",
        "        tail_t_new_len = int(t_new_len - head_t_new_len)\n",
        "\n",
        "        head_q_new_len = int(0.25 * q_new_len)\n",
        "        tail_q_new_len = int(q_new_len - head_q_new_len)\n",
        "\n",
        "        head_a_new_len = int(0.25 * a_new_len)\n",
        "        tail_a_new_len = int(a_new_len - head_a_new_len)\n",
        "\n",
        "        title = title[:head_t_new_len] + title[-tail_t_new_len:]\n",
        "        question = question[:head_q_new_len] + question[-tail_q_new_len:]\n",
        "        answer = answer[:head_a_new_len] + answer[-tail_a_new_len:]\n",
        "\n",
        "    return title, question, answer\n",
        "\n",
        "\n",
        "\n",
        "# for category in np.unique(train['category']):\n",
        "#     tokenizer.vocab[f'[{category}]'] = len(tokenizer.vocab)\n",
        "# for host in np.unique(train['host']):\n",
        "#     tokenizer.vocab[f'[{host}]'] = len(tokenizer.vocab)\n",
        "# tokenizer.vocab['[category_unk]'] = len(tokenizer.vocab)\n",
        "# tokenizer.vocab['[host_unk]'] = len(tokenizer.vocab)\n",
        "\n",
        "def q_trim(tokens, max_length=MAXLEN):\n",
        "# def q_trim(q_, a_, max_length=MAXLEN):\n",
        "    if len(tokens) > max_length:\n",
        "        head_length = int(0.25 * max_length)\n",
        "        tail_length = max_length - head_length\n",
        "        tokens = tokens[:head_length] + tokens[-tail_length:]\n",
        "    return tokens\n",
        "    # if len(q_) >= int(max_length*0.7):\n",
        "    #     head_length = int(0.25 * int(max_length*0.7))\n",
        "    #     tail_length = int(max_length*0.7) - head_length\n",
        "    #     q_ = q_[:head_length] + q_[-tail_length:]\n",
        "\n",
        "    # if len(q_) + len(a_) > max_length:\n",
        "    #     a_length = max_length - len(q_)\n",
        "    #     head_a_length = int(0.25*a_length)\n",
        "    #     tail_a_length = a_length - head_a_length\n",
        "    #     a_ = a_[:head_a_length] + a_[-tail_a_length:]\n",
        "    # return q_, a_\n",
        "\n",
        "def a_trim(q_, a_, max_length=MAXLEN):\n",
        "    a_max_length = int(max_length*0.75)\n",
        "    if len(a_) >= a_max_length:\n",
        "        head_length = int(0.25 * a_max_length)\n",
        "        tail_length = a_max_length - head_length\n",
        "        a_ = a_[:head_length] + a_[-tail_length:]\n",
        "\n",
        "    if len(q_) + len(a_) > max_length:\n",
        "        q_length = max_length - len(a_)\n",
        "        head_q_length = int(0.25*q_length)\n",
        "        tail_q_length = q_length - head_q_length\n",
        "        q_ = q_[:head_q_length] + q_[-tail_q_length:]\n",
        "    return q_, a_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdbE1aufyFmS",
        "colab_type": "text"
      },
      "source": [
        "## Roberta Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-hHcoKR8biQ",
        "colab_type": "text"
      },
      "source": [
        "### Roberta tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh-Vuc6I77ON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
        "\n",
        "def convert_roberta(data_df, model, targets, branch='training'):\n",
        "    data_df = data_df.reset_index(drop=True)\n",
        "    global tokenizer\n",
        "    global MAXLEN\n",
        "    global target_col\n",
        "    ids = []\n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        a = tokenizer.tokenize(data_df.loc[i, 'question_title'])\n",
        "        b = tokenizer.tokenize(data_df.loc[i, 'question_body'])\n",
        "        c = tokenizer.tokenize(data_df.loc[i, 'answer'])\n",
        "        if model == 'qa':\n",
        "            a, b, c = _trim_input(a, b, c, t_max_len=15, q_max_len=244, a_max_len=247)\n",
        "            question = tokenizer.encode(a+b)\n",
        "            answer = tokenizer.encode(c)\n",
        "            ids.append(question+answer)\n",
        "        if model == 'q':\n",
        "            question = tokenizer.encode(a+b)\n",
        "            # answer = tokenizer.convert_tokens_to_ids(['[AN]']+c+['[SEP]'])\n",
        "            question_trim = q_trim(question)\n",
        "            ids.append(question_trim)\n",
        "        if model == 'a':\n",
        "            question = tokenizer.encode(a+b)\n",
        "            answer = tokenizer.encode(c)      \n",
        "            question_trim, answer_trim = a_trim(question, answer)\n",
        "            ids.append(question_trim + answer_trim)\n",
        "    aux = data_df[['category', 'host']]    \n",
        "    if branch == 'training':\n",
        "        targets = data_df[targets]\n",
        "        return ids, np.array(aux, dtype='int32'), np.array(targets)\n",
        "        # return [ids, segments], np.array(targets)\n",
        "    else:\n",
        "        return ids, np.array(aux, dtype='int32')\n",
        "        # return [ids, segments]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyF4rUz-Apf3",
        "colab_type": "text"
      },
      "source": [
        "### Roberta generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRkDqZms_K5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"## Data Generator\"\"\"\n",
        "def seq_padding(X, padding=0):\n",
        "    L = [len(x) for x in X]\n",
        "    ML = min(max(L), MAXLEN)\n",
        "    # ML = MAXLEN\n",
        "    out = np.array([np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x[:ML] for x in X])\n",
        "    return tf.convert_to_tensor(out, dtype=tf.int32)\n",
        "    \n",
        "class roberta_generator:\n",
        "    def __init__(self, data, batch_size=BATCH_SIZE, branch='train', multi_target=True):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.branch = branch\n",
        "        self.steps = len(self.data) // self.batch_size\n",
        "        self.multi_target=multi_target\n",
        "        if len(self.data) % self.batch_size != 0:\n",
        "            self.steps += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "\n",
        "    def __iter__(self):\n",
        "        while True:\n",
        "            if self.branch == 'train':\n",
        "                np.random.shuffle(self.data)\n",
        "            for i in range(self.steps):\n",
        "                d = self.data[i * self.batch_size: (i + 1) * self.batch_size]\n",
        "                X1 = seq_padding([x[0] for x in d])\n",
        "                aux = np.array([x[1][0] for x in d]).reshape(-1, 1)\n",
        "                aux = tf.convert_to_tensor(aux, dtype=tf.int32)\n",
        "                aux2 = np.array([x[1][1] for x in d]).reshape(-1, 1)\n",
        "                aux2 = tf.convert_to_tensor(aux2, dtype=tf.int32)\n",
        "                if self.branch != 'train':\n",
        "                    yield [X1, aux, aux2]\n",
        "                else:                    \n",
        "                    if self.multi_target:\n",
        "                        Y = []\n",
        "                        num_targets = int(d[0][2].shape[0] / 2)\n",
        "                        for i in range(num_targets):\n",
        "                            Y.append(tf.convert_to_tensor([x[2][[i, i+num_targets]] for x in d], dtype=tf.float32))\n",
        "                    else:\n",
        "                        Y = tf.convert_to_tensor([x[2] for x in d], dtype=tf.float32)\n",
        "                    yield [X1, aux, aux2], Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_6YaPDXB1X8",
        "colab_type": "text"
      },
      "source": [
        "### Roberta model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tvcs8dTB3Md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    return keras.metrics.binary_crossentropy(tf.reshape(y_true[:,0],(-1,1)), y_pred) * y_true[:,1]\n",
        "\n",
        "def roberta_build(len_train, num_targets, dropout=0.2, lr=LR, epochs=NUM_EPOCHS, roberta_trainable=True, multi_target=True):\n",
        " \n",
        "    input_text = keras.layers.Input((None,), dtype=tf.int32, name='input_text')\n",
        "    input_category = keras.layers.Input((1,), dtype=tf.int32, name='input_category')\n",
        "    input_host = tf.keras.layers.Input((1,), dtype=tf.int32, name='input_host')\n",
        "\n",
        "    roberta_model = TFAlbertModel.from_pretrained(model_path, trainable=roberta_trainable)\n",
        "    q_outputs = roberta_model(input_text)[0]\n",
        "    q_outputs1 = keras.layers.GlobalAveragePooling1D()(q_outputs)\n",
        "    q_outputs1 = keras.layers.Dropout(dropout)(q_outputs1)\n",
        "\n",
        "    category_emb = keras.layers.Embedding(input_dim=len(category_encoder.mapper)+1, output_dim=32)(input_category)\n",
        "    category_emb = keras.layers.SpatialDropout1D(0.1)(category_emb)\n",
        "\n",
        "    host_emb = keras.layers.Embedding(input_dim=len(host_encoder.mapper)+2, output_dim=32)(input_host)\n",
        "    host_emb = keras.layers.SpatialDropout1D(0.1)(host_emb)\n",
        "\n",
        "    features_dense = keras.layers.concatenate([category_emb, host_emb], axis=1)\n",
        "    features_dense = keras.layers.Flatten()(features_dense)\n",
        "\n",
        "    dense = keras.layers.concatenate([q_outputs1, features_dense])\n",
        "\n",
        "    if multi_target:\n",
        "        # outputs = [keras.layers.Lambda(transfer)(keras.layers.Dense(1, activation='sigmoid')(dense)) for _ in range(num_targets)]\n",
        "        outputs = [keras.layers.Dense(1, activation='sigmoid')(dense) for _ in range(num_targets)]\n",
        "        loss_func = [custom_loss]*num_targets\n",
        "\n",
        "    else:\n",
        "        # outputs = keras.layers.Lambda(transfer)(keras.layers.Dense(num_targets, activation='sigmoid')(dense))\n",
        "        outputs = keras.layers.Dense(num_targets, activation='sigmoid')(dense)\n",
        "        loss_func = ['binary_crossentropy']\n",
        "    # model = keras.Model([q_in, q2_in, q3_in], outputs)\n",
        "    model = keras.Model([input_text, input_category, input_host], outputs)\n",
        "\n",
        "\n",
        "    decay_steps, warmup_steps = calc_train_steps(\n",
        "        len_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=epochs,\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss=loss_func,\n",
        "        optimizer=AdamWarmup(\n",
        "            decay_steps=decay_steps,\n",
        "            warmup_steps=warmup_steps,\n",
        "            lr=lr,\n",
        "            min_lr=MIN_LR,\n",
        "            ),\n",
        "        # optimizer = optimizer_lamb.LAMB(learning_rate=lr)\n",
        "        )\n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I4Pm0MgEbRv",
        "colab_type": "text"
      },
      "source": [
        "### Roberta callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veaCo1qsEdUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kf = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1627)\n",
        "def compute_spearmanr(trues, preds):\n",
        "    rhos = []\n",
        "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
        "        rhos.append(spearmanr(col_trues, col_pred).correlation)\n",
        "    # rho_df = pd.DataFrame(dict(col=cols, rhos=rhos))\n",
        "    return np.nanmean(rhos)#, rho_df\n",
        "\n",
        "class IntervalEval(keras.callbacks.Callback):\n",
        "    def __init__(self, save_model, rho_init=-1, multi_target=True):\n",
        "        global NUM_EPOCHS\n",
        "        super().__init__()\n",
        "        self.rho = []\n",
        "        self.model_weights = []\n",
        "        self.save_model = save_model\n",
        "        self.multi_target = multi_target\n",
        "        self.rho_init = rho_init\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        val_pred = self.model.predict_generator(valid_D.__iter__(), len(valid_D), verbose=1)\n",
        "        if self.multi_target:\n",
        "            val_pred = np.array(val_pred).squeeze().T\n",
        "        nunique = [i for i in range(val_pred.shape[1]) if len(np.unique(val_pred[:, i]))==1]\n",
        "        if len(nunique)>0:\n",
        "            print(f'{len(nunique)} cols with monotonous preds!')\n",
        "        score = compute_spearmanr(val_pred, val_y)\n",
        "        print('Spearman - {:.5f}'.format(score))\n",
        "        if score>self.rho_init:\n",
        "            self.rho_init = score\n",
        "            print('Save Weights')\n",
        "            self.model.save_weights('drive/My Drive/GoogleQA/Models/{:}/{:}-{:}.h5'.format(save_path, self.save_model, i))\n",
        "        self.rho.append(score)\n",
        "        self.model_weights.append(self.model.get_weights())\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        \"\"\"\n",
        "        Weighted average of weights from two best epochs\n",
        "\n",
        "        \"\"\"\n",
        "        rho_selected = np.argsort(self.rho)[-2:]\n",
        "        print(f'Best epoch {rho_selected[1]+1} and second best epoch {rho_selected[0]+1} selected')\n",
        "        swa_weights = [x * 0.3 + y * 0.7 for x, y in zip(self.model_weights[rho_selected[0]], self.model_weights[rho_selected[1]])]\n",
        "        self.model.set_weights(swa_weights)\n",
        "        val_pred = self.model.predict_generator(valid_D.__iter__(), len(valid_D), verbose=1)\n",
        "        if self.multi_target:\n",
        "            val_pred = np.array(val_pred).squeeze().T\n",
        "        nunique = [i for i in range(val_pred.shape[1]) if len(np.unique(val_pred[:, i]))==1]\n",
        "        if len(nunique)>0:\n",
        "            print(f'{len(nunique)} cols with monotonous preds!')\n",
        "        score = compute_spearmanr(val_pred, val_y)\n",
        "        print('SWD Model Spearman - {:.5f}'.format(score))\n",
        "        if score>self.rho_init:\n",
        "            self.rho_init = score\n",
        "            print('Save SWD Weights')\n",
        "            self.model.save_weights('drive/My Drive/GoogleQA/Models/{:}/{:}-{:}.h5'.format(save_path, self.save_model, i))\n",
        "        del self.rho, self.model_weights, swa_weights\n",
        "        gc.collect()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_3Ckfb-C4NG",
        "colab_type": "text"
      },
      "source": [
        "### Roberta Q model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kODVS1gFC6Es",
        "colab_type": "code",
        "outputId": "738e6ed7-79bf-4d37-a83e-c84c00277293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kf = RepeatedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "idx_q = [x for x in kf.split(train, groups=train.question_title)]\n",
        "multi_target = True\n",
        "\n",
        "for i, (tr_idx, val_idx) in enumerate(idx_q[1:], 2):\n",
        "    keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    print('\\nFold - {:}\\n'.format(i))\n",
        "    tr, val = train.loc[tr_idx], train.loc[val_idx]\n",
        "    tr = q_avg(tr)\n",
        "    tr = label_wt(tr, q_col)\n",
        "\n",
        "    tr_x, tr_aux, tr_y = convert_roberta(tr, model='q', targets=q_col+q_col_wt)\n",
        "    val_x, val_aux, val_y = convert_roberta(val, model='q', targets=q_col)\n",
        "\n",
        "    if sum(val[q_col].nunique()==1)>0:\n",
        "        print(f'\\n{sum(val[q_col].nunique()==1)} with Monotonous Label Detected!\\n')\n",
        "\n",
        "    train_D = roberta_generator(list(zip(tr_x, tr_aux, tr_y)), multi_target=multi_target)\n",
        "    valid_D = roberta_generator(list(zip(val_x, val_aux)), branch='valid', multi_target=multi_target)\n",
        "    \n",
        "    # stage 1 fine tunning\n",
        "    ieval = IntervalEval(save_model=save_model+'_q', multi_target=multi_target)\n",
        "    model = roberta_build(\n",
        "        len_train=len(tr), \n",
        "        num_targets=len(q_col), \n",
        "        multi_target=multi_target,\n",
        "        dropout=0.1,\n",
        "        )\n",
        "    model.fit_generator(\n",
        "        train_D.__iter__(),\n",
        "        steps_per_epoch=len(train_D),\n",
        "        epochs=NUM_EPOCHS,\n",
        "        callbacks = [ieval]\n",
        "    )   \n",
        "    rho_stage1 = ieval.rho_init\n",
        "\n",
        "    # stage 2 fine tunning\n",
        "    ieval = IntervalEval(save_model=save_model+'_q', multi_target=multi_target, rho_init=rho_stage1)\n",
        "    model = roberta_build(\n",
        "        len_train=len(tr), \n",
        "        num_targets=len(q_col), \n",
        "        lr=1e-4, \n",
        "        roberta_trainable=False, \n",
        "        multi_target=multi_target,\n",
        "        dropout=0.1,\n",
        "        )\n",
        "    model.load_weights('drive/My Drive/GoogleQA/Models/{:}/{:}-{:}.h5'.format(save_path, save_model+'_q', i))\n",
        "\n",
        "    model.fit_generator(\n",
        "        train_D.__iter__(),\n",
        "        steps_per_epoch=len(train_D),\n",
        "        epochs=4,\n",
        "        callbacks = [ieval]\n",
        "    )\n",
        "\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3163 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold - 2\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3163/3163 [00:04<00:00, 685.25it/s]\n",
            "100%|██████████| 1216/1216 [00:01<00:00, 648.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train for 791 steps\n",
            "Epoch 1/4\n",
            "304/304 [==============================] - 38s 125ms/step\n",
            "Spearman - 0.38360\n",
            "Save Weights\n",
            "791/791 [==============================] - 442s 558ms/step - loss: 11.2110 - dense_loss: 0.4538 - dense_1_loss: 0.8950 - dense_2_loss: 0.3269 - dense_3_loss: 0.7561 - dense_4_loss: 0.5998 - dense_5_loss: 0.5787 - dense_6_loss: 0.8250 - dense_7_loss: 0.8500 - dense_8_loss: 0.6001 - dense_9_loss: 0.1111 - dense_10_loss: 0.8290 - dense_11_loss: 0.7726 - dense_12_loss: 0.2684 - dense_13_loss: 0.1230 - dense_14_loss: 0.1926 - dense_15_loss: 0.3282 - dense_16_loss: 0.6416 - dense_17_loss: 0.5416 - dense_18_loss: 0.7290 - dense_19_loss: 0.0329 - dense_20_loss: 0.7556\n",
            "Epoch 2/4\n",
            "304/304 [==============================] - 36s 120ms/step\n",
            "Spearman - 0.42096\n",
            "Save Weights\n",
            "791/791 [==============================] - 403s 510ms/step - loss: 9.2117 - dense_loss: 0.4176 - dense_1_loss: 0.7711 - dense_2_loss: 0.2145 - dense_3_loss: 0.6506 - dense_4_loss: 0.5493 - dense_5_loss: 0.4774 - dense_6_loss: 0.8020 - dense_7_loss: 0.8003 - dense_8_loss: 0.5130 - dense_9_loss: 0.0539 - dense_10_loss: 0.7048 - dense_11_loss: 0.4838 - dense_12_loss: 0.1486 - dense_13_loss: 0.0767 - dense_14_loss: 0.1237 - dense_15_loss: 0.2353 - dense_16_loss: 0.5177 - dense_17_loss: 0.4976 - dense_18_loss: 0.5513 - dense_19_loss: 0.0107 - dense_20_loss: 0.6118\n",
            "Epoch 3/4\n",
            "304/304 [==============================] - 36s 119ms/step\n",
            "Spearman - 0.43212\n",
            "Save Weights\n",
            "791/791 [==============================] - 405s 512ms/step - loss: 8.7585 - dense_loss: 0.4090 - dense_1_loss: 0.7580 - dense_2_loss: 0.1882 - dense_3_loss: 0.6283 - dense_4_loss: 0.5239 - dense_5_loss: 0.4506 - dense_6_loss: 0.7984 - dense_7_loss: 0.7915 - dense_8_loss: 0.4719 - dense_9_loss: 0.0516 - dense_10_loss: 0.6648 - dense_11_loss: 0.4406 - dense_12_loss: 0.1274 - dense_13_loss: 0.0647 - dense_14_loss: 0.1029 - dense_15_loss: 0.2055 - dense_16_loss: 0.4793 - dense_17_loss: 0.4761 - dense_18_loss: 0.5165 - dense_19_loss: 0.0090 - dense_20_loss: 0.6004\n",
            "Epoch 4/4\n",
            "304/304 [==============================] - 36s 119ms/step\n",
            "Spearman - 0.43413\n",
            "Save Weights\n",
            "791/791 [==============================] - 407s 514ms/step - loss: 8.3765 - dense_loss: 0.4018 - dense_1_loss: 0.7453 - dense_2_loss: 0.1682 - dense_3_loss: 0.6097 - dense_4_loss: 0.4990 - dense_5_loss: 0.4179 - dense_6_loss: 0.7959 - dense_7_loss: 0.7866 - dense_8_loss: 0.4337 - dense_9_loss: 0.0485 - dense_10_loss: 0.6315 - dense_11_loss: 0.4028 - dense_12_loss: 0.1091 - dense_13_loss: 0.0541 - dense_14_loss: 0.0908 - dense_15_loss: 0.1809 - dense_16_loss: 0.4539 - dense_17_loss: 0.4609 - dense_18_loss: 0.4882 - dense_19_loss: 0.0076 - dense_20_loss: 0.5901\n",
            "Best epoch 4 and second best epoch 3 selected\n",
            "304/304 [==============================] - 37s 121ms/step\n",
            "SWD Model Spearman - 0.43543\n",
            "Save SWD Weights\n",
            "Train for 791 steps\n",
            "Epoch 1/4\n",
            "304/304 [==============================] - 38s 125ms/step\n",
            "Spearman - 0.43592\n",
            "Save Weights\n",
            "791/791 [==============================] - 184s 232ms/step - loss: 8.2241 - dense_21_loss: 0.3990 - dense_22_loss: 0.7407 - dense_23_loss: 0.1621 - dense_24_loss: 0.5991 - dense_25_loss: 0.4896 - dense_26_loss: 0.4028 - dense_27_loss: 0.7924 - dense_28_loss: 0.7812 - dense_29_loss: 0.4189 - dense_30_loss: 0.0461 - dense_31_loss: 0.6193 - dense_32_loss: 0.3902 - dense_33_loss: 0.1025 - dense_34_loss: 0.0519 - dense_35_loss: 0.0855 - dense_36_loss: 0.1728 - dense_37_loss: 0.4465 - dense_38_loss: 0.4560 - dense_39_loss: 0.4748 - dense_40_loss: 0.0070 - dense_41_loss: 0.5861\n",
            "Epoch 2/4\n",
            "304/304 [==============================] - 36s 119ms/step\n",
            "Spearman - 0.43640\n",
            "Save Weights\n",
            "791/791 [==============================] - 164s 207ms/step - loss: 8.2107 - dense_21_loss: 0.3978 - dense_22_loss: 0.7394 - dense_23_loss: 0.1608 - dense_24_loss: 0.5991 - dense_25_loss: 0.4886 - dense_26_loss: 0.4037 - dense_27_loss: 0.7942 - dense_28_loss: 0.7808 - dense_29_loss: 0.4186 - dense_30_loss: 0.0456 - dense_31_loss: 0.6144 - dense_32_loss: 0.3891 - dense_33_loss: 0.1025 - dense_34_loss: 0.0507 - dense_35_loss: 0.0859 - dense_36_loss: 0.1710 - dense_37_loss: 0.4464 - dense_38_loss: 0.4534 - dense_39_loss: 0.4769 - dense_40_loss: 0.0059 - dense_41_loss: 0.5856\n",
            "Epoch 3/4\n",
            "304/304 [==============================] - 36s 120ms/step\n",
            "Spearman - 0.43635\n",
            "791/791 [==============================] - 162s 205ms/step - loss: 8.1987 - dense_21_loss: 0.3979 - dense_22_loss: 0.7397 - dense_23_loss: 0.1611 - dense_24_loss: 0.5974 - dense_25_loss: 0.4866 - dense_26_loss: 0.4020 - dense_27_loss: 0.7932 - dense_28_loss: 0.7803 - dense_29_loss: 0.4171 - dense_30_loss: 0.0447 - dense_31_loss: 0.6162 - dense_32_loss: 0.3879 - dense_33_loss: 0.1028 - dense_34_loss: 0.0505 - dense_35_loss: 0.0856 - dense_36_loss: 0.1719 - dense_37_loss: 0.4444 - dense_38_loss: 0.4539 - dense_39_loss: 0.4739 - dense_40_loss: 0.0058 - dense_41_loss: 0.5857\n",
            "Epoch 4/4\n",
            "304/304 [==============================] - 37s 121ms/step\n",
            "Spearman - 0.43633\n",
            "791/791 [==============================] - 162s 205ms/step - loss: 8.2003 - dense_21_loss: 0.3971 - dense_22_loss: 0.7401 - dense_23_loss: 0.1618 - dense_24_loss: 0.5953 - dense_25_loss: 0.4877 - dense_26_loss: 0.4026 - dense_27_loss: 0.7935 - dense_28_loss: 0.7797 - dense_29_loss: 0.4176 - dense_30_loss: 0.0446 - dense_31_loss: 0.6169 - dense_32_loss: 0.3892 - dense_33_loss: 0.1014 - dense_34_loss: 0.0505 - dense_35_loss: 0.0862 - dense_36_loss: 0.1711 - dense_37_loss: 0.4469 - dense_38_loss: 0.4552 - dense_39_loss: 0.4723 - dense_40_loss: 0.0055 - dense_41_loss: 0.5852\n",
            "Best epoch 2 and second best epoch 3 selected\n",
            "304/304 [==============================] - 37s 121ms/step\n",
            "SWD Model Spearman - 0.43640\n",
            "Save SWD Weights\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold - 3\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3180/3180 [00:04<00:00, 686.67it/s]\n",
            "100%|██████████| 1216/1216 [00:02<00:00, 600.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train for 795 steps\n",
            "Epoch 1/4\n",
            "304/304 [==============================] - 37s 123ms/step\n",
            "Spearman - 0.38749\n",
            "Save Weights\n",
            "795/795 [==============================] - 447s 562ms/step - loss: 11.0364 - dense_loss: 0.4520 - dense_1_loss: 0.9296 - dense_2_loss: 0.2662 - dense_3_loss: 0.6950 - dense_4_loss: 0.6671 - dense_5_loss: 0.5516 - dense_6_loss: 0.8222 - dense_7_loss: 0.8144 - dense_8_loss: 0.6425 - dense_9_loss: 0.0890 - dense_10_loss: 0.8808 - dense_11_loss: 0.6968 - dense_12_loss: 0.2274 - dense_13_loss: 0.0998 - dense_14_loss: 0.3320 - dense_15_loss: 0.3106 - dense_16_loss: 0.6329 - dense_17_loss: 0.5258 - dense_18_loss: 0.7357 - dense_19_loss: 0.0319 - dense_20_loss: 0.6331\n",
            "Epoch 2/4\n",
            "304/304 [==============================] - 36s 118ms/step\n",
            "Spearman - 0.42163\n",
            "Save Weights\n",
            "795/795 [==============================] - 411s 518ms/step - loss: 9.2291 - dense_loss: 0.4178 - dense_1_loss: 0.7763 - dense_2_loss: 0.2002 - dense_3_loss: 0.6541 - dense_4_loss: 0.5457 - dense_5_loss: 0.5124 - dense_6_loss: 0.7964 - dense_7_loss: 0.7932 - dense_8_loss: 0.5322 - dense_9_loss: 0.0573 - dense_10_loss: 0.6981 - dense_11_loss: 0.4810 - dense_12_loss: 0.1563 - dense_13_loss: 0.0828 - dense_14_loss: 0.1175 - dense_15_loss: 0.2354 - dense_16_loss: 0.4993 - dense_17_loss: 0.4920 - dense_18_loss: 0.5620 - dense_19_loss: 0.0129 - dense_20_loss: 0.6060\n",
            "Epoch 3/4\n",
            "304/304 [==============================] - 36s 119ms/step\n",
            "Spearman - 0.43156\n",
            "Save Weights\n",
            "795/795 [==============================] - 409s 515ms/step - loss: 8.7453 - dense_loss: 0.4089 - dense_1_loss: 0.7558 - dense_2_loss: 0.1728 - dense_3_loss: 0.6306 - dense_4_loss: 0.5149 - dense_5_loss: 0.4819 - dense_6_loss: 0.7931 - dense_7_loss: 0.7878 - dense_8_loss: 0.4882 - dense_9_loss: 0.0536 - dense_10_loss: 0.6579 - dense_11_loss: 0.4268 - dense_12_loss: 0.1256 - dense_13_loss: 0.0725 - dense_14_loss: 0.1005 - dense_15_loss: 0.2058 - dense_16_loss: 0.4630 - dense_17_loss: 0.4788 - dense_18_loss: 0.5199 - dense_19_loss: 0.0112 - dense_20_loss: 0.5956\n",
            "Epoch 4/4\n",
            "304/304 [==============================] - 36s 119ms/step\n",
            "Spearman - 0.43412\n",
            "Save Weights\n",
            "795/795 [==============================] - 411s 517ms/step - loss: 8.3438 - dense_loss: 0.4024 - dense_1_loss: 0.7460 - dense_2_loss: 0.1521 - dense_3_loss: 0.6050 - dense_4_loss: 0.4941 - dense_5_loss: 0.4478 - dense_6_loss: 0.7902 - dense_7_loss: 0.7797 - dense_8_loss: 0.4422 - dense_9_loss: 0.0479 - dense_10_loss: 0.6173 - dense_11_loss: 0.3968 - dense_12_loss: 0.1120 - dense_13_loss: 0.0595 - dense_14_loss: 0.0909 - dense_15_loss: 0.1777 - dense_16_loss: 0.4359 - dense_17_loss: 0.4620 - dense_18_loss: 0.4888 - dense_19_loss: 0.0100 - dense_20_loss: 0.5855\n",
            "Best epoch 4 and second best epoch 3 selected\n",
            "304/304 [==============================] - 36s 120ms/step\n",
            "SWD Model Spearman - 0.43530\n",
            "Save SWD Weights\n",
            "Train for 795 steps\n",
            "Epoch 1/4\n",
            "304/304 [==============================] - 38s 124ms/step\n",
            "Spearman - 0.43640\n",
            "Save Weights\n",
            "795/795 [==============================] - 186s 234ms/step - loss: 8.1914 - dense_21_loss: 0.3997 - dense_22_loss: 0.7404 - dense_23_loss: 0.1477 - dense_24_loss: 0.5977 - dense_25_loss: 0.4827 - dense_26_loss: 0.4349 - dense_27_loss: 0.7888 - dense_28_loss: 0.7762 - dense_29_loss: 0.4245 - dense_30_loss: 0.0464 - dense_31_loss: 0.6051 - dense_32_loss: 0.3821 - dense_33_loss: 0.1056 - dense_34_loss: 0.0557 - dense_35_loss: 0.0852 - dense_36_loss: 0.1706 - dense_37_loss: 0.4271 - dense_38_loss: 0.4549 - dense_39_loss: 0.4770 - dense_40_loss: 0.0088 - dense_41_loss: 0.5804\n",
            "Epoch 2/4\n",
            "304/304 [==============================] - 36s 118ms/step\n",
            "Spearman - 0.43694\n",
            "Save Weights\n",
            "795/795 [==============================] - 168s 212ms/step - loss: 8.1731 - dense_21_loss: 0.3992 - dense_22_loss: 0.7398 - dense_23_loss: 0.1462 - dense_24_loss: 0.5950 - dense_25_loss: 0.4830 - dense_26_loss: 0.4360 - dense_27_loss: 0.7875 - dense_28_loss: 0.7770 - dense_29_loss: 0.4258 - dense_30_loss: 0.0453 - dense_31_loss: 0.6051 - dense_32_loss: 0.3820 - dense_33_loss: 0.1038 - dense_34_loss: 0.0539 - dense_35_loss: 0.0836 - dense_36_loss: 0.1679 - dense_37_loss: 0.4240 - dense_38_loss: 0.4534 - dense_39_loss: 0.4748 - dense_40_loss: 0.0086 - dense_41_loss: 0.5813\n",
            "Epoch 3/4\n",
            "304/304 [==============================] - 36s 118ms/step\n",
            "Spearman - 0.43724\n",
            "Save Weights\n",
            "795/795 [==============================] - 168s 212ms/step - loss: 8.1633 - dense_21_loss: 0.3994 - dense_22_loss: 0.7381 - dense_23_loss: 0.1457 - dense_24_loss: 0.5925 - dense_25_loss: 0.4814 - dense_26_loss: 0.4344 - dense_27_loss: 0.7883 - dense_28_loss: 0.7764 - dense_29_loss: 0.4251 - dense_30_loss: 0.0449 - dense_31_loss: 0.6009 - dense_32_loss: 0.3814 - dense_33_loss: 0.1048 - dense_34_loss: 0.0546 - dense_35_loss: 0.0846 - dense_36_loss: 0.1683 - dense_37_loss: 0.4242 - dense_38_loss: 0.4532 - dense_39_loss: 0.4759 - dense_40_loss: 0.0084 - dense_41_loss: 0.5809\n",
            "Epoch 4/4\n",
            "304/304 [==============================] - 36s 119ms/step\n",
            "Spearman - 0.43720\n",
            "795/795 [==============================] - 166s 209ms/step - loss: 8.1510 - dense_21_loss: 0.3985 - dense_22_loss: 0.7383 - dense_23_loss: 0.1462 - dense_24_loss: 0.5927 - dense_25_loss: 0.4814 - dense_26_loss: 0.4328 - dense_27_loss: 0.7880 - dense_28_loss: 0.7742 - dense_29_loss: 0.4238 - dense_30_loss: 0.0456 - dense_31_loss: 0.6008 - dense_32_loss: 0.3813 - dense_33_loss: 0.1044 - dense_34_loss: 0.0537 - dense_35_loss: 0.0826 - dense_36_loss: 0.1677 - dense_37_loss: 0.4236 - dense_38_loss: 0.4507 - dense_39_loss: 0.4774 - dense_40_loss: 0.0081 - dense_41_loss: 0.5791\n",
            "Best epoch 3 and second best epoch 4 selected\n",
            "304/304 [==============================] - 36s 119ms/step\n",
            "SWD Model Spearman - 0.43723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3166 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold - 4\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3166/3166 [00:05<00:00, 632.05it/s]\n",
            "100%|██████████| 1216/1216 [00:01<00:00, 651.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train for 792 steps\n",
            "Epoch 1/4\n",
            "304/304 [==============================] - 39s 128ms/step\n",
            "Spearman - 0.38371\n",
            "Save Weights\n",
            "792/792 [==============================] - 444s 561ms/step - loss: 11.2768 - dense_loss: 0.4530 - dense_1_loss: 0.8526 - dense_2_loss: 0.2845 - dense_3_loss: 0.7049 - dense_4_loss: 0.6017 - dense_5_loss: 0.6314 - dense_6_loss: 0.8188 - dense_7_loss: 0.9136 - dense_8_loss: 0.6047 - dense_9_loss: 0.0692 - dense_10_loss: 0.8809 - dense_11_loss: 0.6739 - dense_12_loss: 0.2181 - dense_13_loss: 0.2786 - dense_14_loss: 0.1780 - dense_15_loss: 0.3185 - dense_16_loss: 0.6922 - dense_17_loss: 0.5510 - dense_18_loss: 0.8012 - dense_19_loss: 0.0768 - dense_20_loss: 0.6731\n",
            "Epoch 2/4\n",
            "304/304 [==============================] - 37s 122ms/step\n",
            "Spearman - 0.42716\n",
            "Save Weights\n",
            "792/792 [==============================] - 404s 511ms/step - loss: 9.2330 - dense_loss: 0.4199 - dense_1_loss: 0.7756 - dense_2_loss: 0.2123 - dense_3_loss: 0.6554 - dense_4_loss: 0.5544 - dense_5_loss: 0.5111 - dense_6_loss: 0.8012 - dense_7_loss: 0.8069 - dense_8_loss: 0.5169 - dense_9_loss: 0.0482 - dense_10_loss: 0.7049 - dense_11_loss: 0.4698 - dense_12_loss: 0.1406 - dense_13_loss: 0.0817 - dense_14_loss: 0.1201 - dense_15_loss: 0.2268 - dense_16_loss: 0.5061 - dense_17_loss: 0.4913 - dense_18_loss: 0.5593 - dense_19_loss: 0.0145 - dense_20_loss: 0.6160\n",
            "Epoch 3/4\n",
            "304/304 [==============================] - 37s 123ms/step\n",
            "Spearman - 0.43306\n",
            "Save Weights\n",
            "792/792 [==============================] - 406s 512ms/step - loss: 8.7852 - dense_loss: 0.4141 - dense_1_loss: 0.7601 - dense_2_loss: 0.1842 - dense_3_loss: 0.6303 - dense_4_loss: 0.5254 - dense_5_loss: 0.4751 - dense_6_loss: 0.7978 - dense_7_loss: 0.7980 - dense_8_loss: 0.4746 - dense_9_loss: 0.0449 - dense_10_loss: 0.6673 - dense_11_loss: 0.4293 - dense_12_loss: 0.1246 - dense_13_loss: 0.0678 - dense_14_loss: 0.1022 - dense_15_loss: 0.1986 - dense_16_loss: 0.4756 - dense_17_loss: 0.4778 - dense_18_loss: 0.5209 - dense_19_loss: 0.0123 - dense_20_loss: 0.6043\n",
            "Epoch 4/4\n",
            "304/304 [==============================] - 37s 122ms/step\n",
            "Spearman - 0.43309\n",
            "Save Weights\n",
            "792/792 [==============================] - 405s 511ms/step - loss: 8.4202 - dense_loss: 0.4082 - dense_1_loss: 0.7506 - dense_2_loss: 0.1651 - dense_3_loss: 0.6101 - dense_4_loss: 0.5022 - dense_5_loss: 0.4466 - dense_6_loss: 0.7951 - dense_7_loss: 0.7877 - dense_8_loss: 0.4392 - dense_9_loss: 0.0394 - dense_10_loss: 0.6317 - dense_11_loss: 0.4027 - dense_12_loss: 0.1082 - dense_13_loss: 0.0596 - dense_14_loss: 0.0915 - dense_15_loss: 0.1746 - dense_16_loss: 0.4488 - dense_17_loss: 0.4594 - dense_18_loss: 0.4914 - dense_19_loss: 0.0115 - dense_20_loss: 0.5963\n",
            "Best epoch 4 and second best epoch 3 selected\n",
            "304/304 [==============================] - 37s 123ms/step\n",
            "SWD Model Spearman - 0.43478\n",
            "Save SWD Weights\n",
            "Train for 792 steps\n",
            "Epoch 1/4\n",
            "304/304 [==============================] - 39s 127ms/step\n",
            "Spearman - 0.43565\n",
            "Save Weights\n",
            "792/792 [==============================] - 185s 233ms/step - loss: 8.2700 - dense_21_loss: 0.4032 - dense_22_loss: 0.7472 - dense_23_loss: 0.1577 - dense_24_loss: 0.5986 - dense_25_loss: 0.4920 - dense_26_loss: 0.4332 - dense_27_loss: 0.7937 - dense_28_loss: 0.7859 - dense_29_loss: 0.4240 - dense_30_loss: 0.0402 - dense_31_loss: 0.6187 - dense_32_loss: 0.3908 - dense_33_loss: 0.1053 - dense_34_loss: 0.0566 - dense_35_loss: 0.0864 - dense_36_loss: 0.1684 - dense_37_loss: 0.4356 - dense_38_loss: 0.4530 - dense_39_loss: 0.4782 - dense_40_loss: 0.0102 - dense_41_loss: 0.5910\n",
            "Epoch 2/4\n",
            "304/304 [==============================] - 37s 121ms/step\n",
            "Spearman - 0.43598\n",
            "Save Weights\n",
            "792/792 [==============================] - 168s 212ms/step - loss: 8.2459 - dense_21_loss: 0.4034 - dense_22_loss: 0.7449 - dense_23_loss: 0.1562 - dense_24_loss: 0.5981 - dense_25_loss: 0.4926 - dense_26_loss: 0.4334 - dense_27_loss: 0.7926 - dense_28_loss: 0.7837 - dense_29_loss: 0.4221 - dense_30_loss: 0.0385 - dense_31_loss: 0.6177 - dense_32_loss: 0.3865 - dense_33_loss: 0.1032 - dense_34_loss: 0.0558 - dense_35_loss: 0.0865 - dense_36_loss: 0.1662 - dense_37_loss: 0.4328 - dense_38_loss: 0.4521 - dense_39_loss: 0.4790 - dense_40_loss: 0.0100 - dense_41_loss: 0.5906\n",
            "Epoch 3/4\n",
            "304/304 [==============================] - 37s 121ms/step\n",
            "Spearman - 0.43627\n",
            "Save Weights\n",
            "792/792 [==============================] - 167s 211ms/step - loss: 8.2338 - dense_21_loss: 0.4024 - dense_22_loss: 0.7434 - dense_23_loss: 0.1574 - dense_24_loss: 0.5971 - dense_25_loss: 0.4914 - dense_26_loss: 0.4313 - dense_27_loss: 0.7914 - dense_28_loss: 0.7836 - dense_29_loss: 0.4227 - dense_30_loss: 0.0376 - dense_31_loss: 0.6158 - dense_32_loss: 0.3858 - dense_33_loss: 0.1025 - dense_34_loss: 0.0546 - dense_35_loss: 0.0868 - dense_36_loss: 0.1668 - dense_37_loss: 0.4348 - dense_38_loss: 0.4510 - dense_39_loss: 0.4788 - dense_40_loss: 0.0089 - dense_41_loss: 0.5897\n",
            "Epoch 4/4\n",
            "304/304 [==============================] - 37s 121ms/step\n",
            "Spearman - 0.43625\n",
            "792/792 [==============================] - 165s 209ms/step - loss: 8.2240 - dense_21_loss: 0.4013 - dense_22_loss: 0.7441 - dense_23_loss: 0.1549 - dense_24_loss: 0.5970 - dense_25_loss: 0.4920 - dense_26_loss: 0.4292 - dense_27_loss: 0.7927 - dense_28_loss: 0.7834 - dense_29_loss: 0.4203 - dense_30_loss: 0.0389 - dense_31_loss: 0.6166 - dense_32_loss: 0.3857 - dense_33_loss: 0.1029 - dense_34_loss: 0.0547 - dense_35_loss: 0.0851 - dense_36_loss: 0.1654 - dense_37_loss: 0.4324 - dense_38_loss: 0.4519 - dense_39_loss: 0.4773 - dense_40_loss: 0.0084 - dense_41_loss: 0.5900\n",
            "Best epoch 3 and second best epoch 4 selected\n",
            "304/304 [==============================] - 37s 121ms/step\n",
            "SWD Model Spearman - 0.43627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3186 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold - 5\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3186/3186 [00:04<00:00, 666.53it/s]\n",
            "100%|██████████| 1215/1215 [00:01<00:00, 665.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train for 797 steps\n",
            "Epoch 1/4\n",
            "304/304 [==============================] - 37s 122ms/step\n",
            "Spearman - 0.37541\n",
            "Save Weights\n",
            "797/797 [==============================] - 445s 559ms/step - loss: 11.3719 - dense_loss: 0.5945 - dense_1_loss: 0.7970 - dense_2_loss: 0.3563 - dense_3_loss: 0.7076 - dense_4_loss: 0.6309 - dense_5_loss: 0.6832 - dense_6_loss: 0.8348 - dense_7_loss: 0.8329 - dense_8_loss: 0.6356 - dense_9_loss: 0.0689 - dense_10_loss: 0.8199 - dense_11_loss: 0.6960 - dense_12_loss: 0.2616 - dense_13_loss: 0.2492 - dense_14_loss: 0.1905 - dense_15_loss: 0.3260 - dense_16_loss: 0.7091 - dense_17_loss: 0.5845 - dense_18_loss: 0.6639 - dense_19_loss: 0.0441 - dense_20_loss: 0.6854\n",
            "Epoch 2/4\n",
            "304/304 [==============================] - 35s 117ms/step\n",
            "Spearman - 0.41982\n",
            "Save Weights\n",
            "797/797 [==============================] - 409s 514ms/step - loss: 9.2489 - dense_loss: 0.4212 - dense_1_loss: 0.7635 - dense_2_loss: 0.2144 - dense_3_loss: 0.6635 - dense_4_loss: 0.5512 - dense_5_loss: 0.4883 - dense_6_loss: 0.7980 - dense_7_loss: 0.7947 - dense_8_loss: 0.5442 - dense_9_loss: 0.0534 - dense_10_loss: 0.6966 - dense_11_loss: 0.4857 - dense_12_loss: 0.1516 - dense_13_loss: 0.0806 - dense_14_loss: 0.1166 - dense_15_loss: 0.2230 - dense_16_loss: 0.5225 - dense_17_loss: 0.4983 - dense_18_loss: 0.5537 - dense_19_loss: 0.0129 - dense_20_loss: 0.6150\n",
            "Epoch 3/4\n",
            "304/304 [==============================] - 35s 117ms/step\n",
            "Spearman - 0.42836\n",
            "Save Weights\n",
            "797/797 [==============================] - 408s 512ms/step - loss: 8.7851 - dense_loss: 0.4153 - dense_1_loss: 0.7489 - dense_2_loss: 0.1862 - dense_3_loss: 0.6416 - dense_4_loss: 0.5203 - dense_5_loss: 0.4539 - dense_6_loss: 0.7929 - dense_7_loss: 0.7898 - dense_8_loss: 0.5021 - dense_9_loss: 0.0496 - dense_10_loss: 0.6517 - dense_11_loss: 0.4391 - dense_12_loss: 0.1230 - dense_13_loss: 0.0708 - dense_14_loss: 0.1020 - dense_15_loss: 0.1945 - dense_16_loss: 0.4820 - dense_17_loss: 0.4836 - dense_18_loss: 0.5188 - dense_19_loss: 0.0121 - dense_20_loss: 0.6070\n",
            "Epoch 4/4\n",
            "304/304 [==============================] - 36s 117ms/step\n",
            "Spearman - 0.43212\n",
            "Save Weights\n",
            "797/797 [==============================] - 408s 512ms/step - loss: 8.4108 - dense_loss: 0.4077 - dense_1_loss: 0.7411 - dense_2_loss: 0.1676 - dense_3_loss: 0.6178 - dense_4_loss: 0.4967 - dense_5_loss: 0.4246 - dense_6_loss: 0.7903 - dense_7_loss: 0.7803 - dense_8_loss: 0.4588 - dense_9_loss: 0.0447 - dense_10_loss: 0.6213 - dense_11_loss: 0.4071 - dense_12_loss: 0.1088 - dense_13_loss: 0.0608 - dense_14_loss: 0.0904 - dense_15_loss: 0.1724 - dense_16_loss: 0.4568 - dense_17_loss: 0.4685 - dense_18_loss: 0.4882 - dense_19_loss: 0.0103 - dense_20_loss: 0.5968\n",
            "Best epoch 4 and second best epoch 3 selected\n",
            "304/304 [==============================] - 36s 117ms/step\n",
            "SWD Model Spearman - 0.43279\n",
            "Save SWD Weights\n",
            "Train for 797 steps\n",
            "Epoch 1/4\n",
            "304/304 [==============================] - 37s 122ms/step\n",
            "Spearman - 0.43405\n",
            "Save Weights\n",
            "797/797 [==============================] - 185s 232ms/step - loss: 8.2468 - dense_21_loss: 0.4053 - dense_22_loss: 0.7349 - dense_23_loss: 0.1618 - dense_24_loss: 0.6058 - dense_25_loss: 0.4866 - dense_26_loss: 0.4086 - dense_27_loss: 0.7899 - dense_28_loss: 0.7785 - dense_29_loss: 0.4433 - dense_30_loss: 0.0430 - dense_31_loss: 0.6060 - dense_32_loss: 0.3908 - dense_33_loss: 0.1038 - dense_34_loss: 0.0570 - dense_35_loss: 0.0855 - dense_36_loss: 0.1655 - dense_37_loss: 0.4439 - dense_38_loss: 0.4611 - dense_39_loss: 0.4750 - dense_40_loss: 0.0096 - dense_41_loss: 0.5911\n",
            "Epoch 2/4\n",
            "304/304 [==============================] - 35s 117ms/step\n",
            "Spearman - 0.43348\n",
            "797/797 [==============================] - 166s 208ms/step - loss: 8.2482 - dense_21_loss: 0.4041 - dense_22_loss: 0.7353 - dense_23_loss: 0.1612 - dense_24_loss: 0.6083 - dense_25_loss: 0.4843 - dense_26_loss: 0.4100 - dense_27_loss: 0.7897 - dense_28_loss: 0.7786 - dense_29_loss: 0.4433 - dense_30_loss: 0.0428 - dense_31_loss: 0.6089 - dense_32_loss: 0.3926 - dense_33_loss: 0.1029 - dense_34_loss: 0.0568 - dense_35_loss: 0.0853 - dense_36_loss: 0.1659 - dense_37_loss: 0.4464 - dense_38_loss: 0.4588 - dense_39_loss: 0.4736 - dense_40_loss: 0.0087 - dense_41_loss: 0.5907\n",
            "Epoch 3/4\n",
            "304/304 [==============================] - 35s 117ms/step\n",
            "Spearman - 0.43376\n",
            "797/797 [==============================] - 163s 204ms/step - loss: 8.2288 - dense_21_loss: 0.4043 - dense_22_loss: 0.7341 - dense_23_loss: 0.1598 - dense_24_loss: 0.6056 - dense_25_loss: 0.4858 - dense_26_loss: 0.4067 - dense_27_loss: 0.7874 - dense_28_loss: 0.7766 - dense_29_loss: 0.4446 - dense_30_loss: 0.0423 - dense_31_loss: 0.6083 - dense_32_loss: 0.3911 - dense_33_loss: 0.1012 - dense_34_loss: 0.0570 - dense_35_loss: 0.0847 - dense_36_loss: 0.1632 - dense_37_loss: 0.4451 - dense_38_loss: 0.4594 - dense_39_loss: 0.4745 - dense_40_loss: 0.0086 - dense_41_loss: 0.5886\n",
            "Epoch 4/4\n",
            "304/304 [==============================] - 36s 117ms/step\n",
            "Spearman - 0.43386\n",
            "797/797 [==============================] - 164s 205ms/step - loss: 8.2218 - dense_21_loss: 0.4036 - dense_22_loss: 0.7350 - dense_23_loss: 0.1598 - dense_24_loss: 0.6043 - dense_25_loss: 0.4846 - dense_26_loss: 0.4088 - dense_27_loss: 0.7890 - dense_28_loss: 0.7748 - dense_29_loss: 0.4416 - dense_30_loss: 0.0415 - dense_31_loss: 0.6067 - dense_32_loss: 0.3899 - dense_33_loss: 0.1030 - dense_34_loss: 0.0565 - dense_35_loss: 0.0844 - dense_36_loss: 0.1631 - dense_37_loss: 0.4454 - dense_38_loss: 0.4572 - dense_39_loss: 0.4752 - dense_40_loss: 0.0080 - dense_41_loss: 0.5895\n",
            "Best epoch 1 and second best epoch 4 selected\n",
            "304/304 [==============================] - 36s 117ms/step\n",
            "SWD Model Spearman - 0.43402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9MS89G52uvr",
        "colab_type": "text"
      },
      "source": [
        "### Roberta A model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcZe5idY2xIA",
        "colab_type": "code",
        "outputId": "7490b05c-6b6b-49a0-cf32-dadc6864d851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "kf = RepeatedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "idx_a = [x for x in kf.split(train, groups=train.question_title)]\n",
        "multi_target = True\n",
        "\n",
        "for i, (tr_idx, val_idx) in enumerate(idx_a[3:4], 4):\n",
        "    keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    print('\\nFold - {:}\\n'.format(i))\n",
        "    tr, val = train.loc[tr_idx], train.loc[val_idx]\n",
        "    tr = label_wt(tr, a_col)\n",
        "\n",
        "    tr_x, tr_aux, tr_y = convert_roberta(tr, model='a', targets=a_col+a_col_wt)\n",
        "    val_x, val_aux, val_y = convert_roberta(val, model='a', targets=a_col)\n",
        "\n",
        "    if sum(val[q_col].nunique()==1)>0:\n",
        "        print(f'\\n{sum(val[q_col].nunique()==1)} with Monotonous Label Detected!\\n')\n",
        "\n",
        "    train_D = roberta_generator(list(zip(tr_x, tr_aux, tr_y)), multi_target=multi_target)\n",
        "    valid_D = roberta_generator(list(zip(val_x, val_aux)), branch='valid', multi_target=multi_target)\n",
        "    \n",
        "    # stage 1 fine tunning\n",
        "    ieval = IntervalEval(save_model=save_model+'_a', multi_target=multi_target)\n",
        "    model = roberta_build(\n",
        "        len_train=len(tr), \n",
        "        num_targets=len(a_col), \n",
        "        multi_target=multi_target,\n",
        "        dropout=0.1,\n",
        "        )\n",
        "    model.fit_generator(\n",
        "        train_D.__iter__(),\n",
        "        steps_per_epoch=len(train_D),\n",
        "        epochs=NUM_EPOCHS,\n",
        "        callbacks = [ieval]\n",
        "    )   \n",
        "    rho_stage1 = ieval.rho_init\n",
        "\n",
        "    # stage 2 fine tunning\n",
        "    ieval = IntervalEval(save_model=save_model+'_a', multi_target=multi_target, rho_init=rho_stage1)\n",
        "    model = roberta_build(\n",
        "        len_train=len(tr), \n",
        "        num_targets=len(a_col), \n",
        "        lr=1e-4, \n",
        "        roberta_trainable=False, \n",
        "        multi_target=multi_target,\n",
        "        dropout=0.1,\n",
        "        )\n",
        "    model.load_weights('drive/My Drive/GoogleQA/Models/{:}/{:}-{:}.h5'.format(save_path, save_model+'_a', i))\n",
        "\n",
        "    model.fit_generator(\n",
        "        train_D.__iter__(),\n",
        "        steps_per_epoch=len(train_D),\n",
        "        epochs=4,\n",
        "        callbacks = [ieval]\n",
        "    )\n",
        "\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 55/4863 [00:00<00:08, 538.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold - 4\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4863/4863 [00:07<00:00, 626.16it/s]\n",
            "100%|██████████| 1216/1216 [00:02<00:00, 582.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train for 1216 steps\n",
            "Epoch 1/4\n",
            "304/304 [==============================] - 79s 261ms/step\n",
            "Spearman - 0.32116\n",
            "Save Weights\n",
            "1216/1216 [==============================] - 1440s 1s/step - loss: 4.1047 - dense_loss: 0.3018 - dense_1_loss: 0.7373 - dense_2_loss: 0.2214 - dense_3_loss: 0.1868 - dense_4_loss: 0.4972 - dense_5_loss: 0.6074 - dense_6_loss: 0.4919 - dense_7_loss: 0.6395 - dense_8_loss: 0.4214\n",
            "Epoch 2/4\n",
            "304/304 [==============================] - 78s 255ms/step\n",
            "Spearman - 0.33743\n",
            "Save Weights\n",
            "1216/1216 [==============================] - 1387s 1s/step - loss: 3.6100 - dense_loss: 0.2878 - dense_1_loss: 0.7001 - dense_2_loss: 0.2122 - dense_3_loss: 0.1724 - dense_4_loss: 0.4801 - dense_5_loss: 0.4665 - dense_6_loss: 0.4000 - dense_7_loss: 0.5441 - dense_8_loss: 0.3468\n",
            "Epoch 3/4\n",
            "304/304 [==============================] - 78s 256ms/step\n",
            "Spearman - 0.34258\n",
            "Save Weights\n",
            "1216/1216 [==============================] - 1393s 1s/step - loss: 3.4394 - dense_loss: 0.2786 - dense_1_loss: 0.6943 - dense_2_loss: 0.2056 - dense_3_loss: 0.1651 - dense_4_loss: 0.4686 - dense_5_loss: 0.4144 - dense_6_loss: 0.3875 - dense_7_loss: 0.4824 - dense_8_loss: 0.3429\n",
            "Epoch 4/4\n",
            " 389/1216 [========>.....................] - ETA: 14:54 - loss: 3.2140 - dense_loss: 0.2584 - dense_1_loss: 0.6850 - dense_2_loss: 0.1923 - dense_3_loss: 0.1449 - dense_4_loss: 0.4449 - dense_5_loss: 0.3662 - dense_6_loss: 0.3753 - dense_7_loss: 0.4080 - dense_8_loss: 0.3389"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEbrwroXNhPm",
        "colab_type": "text"
      },
      "source": [
        "### oof pred"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe-au4mQNi3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# oof-prediction\n",
        "multi_target = True\n",
        "model_q = roberta_build(len_train=len(train), num_targets=len(q_col), multi_target=multi_target)\n",
        "model_a = roberta_build(len_train=len(train), num_targets=len(a_col), multi_target=multi_target)\n",
        "oof_pred_q = train[['qa_id']+q_col].copy()\n",
        "oof_pred_q[q_col] = 0\n",
        "oof_pred_a = train[['qa_id']+a_col].copy()\n",
        "oof_pred_a[a_col] = 0\n",
        "\n",
        "\n",
        "kf = RepeatedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "idx_q = [x for x in kf.split(train, groups=train.question_title)]\n",
        "for i, (tr_idx, val_idx) in enumerate(idx_q, 1):\n",
        "    print('\\nFold - {:}\\n'.format(i))\n",
        "    tr, val = train.loc[tr_idx], train.loc[val_idx]\n",
        "    val_x, val_aux, val_y = convert_roberta(val, 'q', targets=q_col)\n",
        "    valid_D = roberta_generator(list(zip(val_x, val_aux)), branch='valid', multi_target=multi_target)\n",
        "    model_q.load_weights('drive/My Drive/GoogleQA/Models/{}/{}-{}.h5'.format(save_path, save_model+'_q', i))\n",
        "    val_pred_q = model_q.predict_generator(valid_D.__iter__(), len(valid_D), verbose=1)\n",
        "    oof_pred_q.loc[val_idx, q_col] += np.array(val_pred_q).squeeze().T# / 2\n",
        "    score = compute_spearmanr(val_y, np.array(val_pred_q).squeeze().T)\n",
        "    print('\\nQ - Spearman - {:.5f}\\n'.format(score))\n",
        "\n",
        "idx_a = [x for x in kf.split(train, groups=train.question_title)]\n",
        "for i, (tr_idx, val_idx) in enumerate(idx_a, 1):\n",
        "    print('\\nFold - {:}\\n'.format(i))\n",
        "    tr, val = train.loc[tr_idx], train.loc[val_idx]\n",
        "    val_x, val_aux, val_y = convert_roberta(val, 'a', targets=a_col)\n",
        "    valid_D = roberta_generator(list(zip(val_x, val_aux)), branch='valid', multi_target=multi_target)\n",
        "    model_a.load_weights('drive/My Drive/GoogleQA/Models/{}/{}-{}.h5'.format(save_path, save_model+'_a', i))\n",
        "    val_pred_a = model_a.predict_generator(valid_D.__iter__(), len(valid_D), verbose=1)\n",
        "    oof_pred_a.loc[val_idx, a_col] += np.array(val_pred_a).squeeze().T\n",
        "    score = compute_spearmanr(val_y, np.array(val_pred_a).squeeze().T)\n",
        "    print('\\nA - Spearman - {:.5f}\\n'.format(score))\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "oof_pred_qa_sep = pd.concat([oof_pred_q, oof_pred_a[a_col]], axis=1)\n",
        "# oof_pred = oof_pred_qa[target_col].values * 0.4 + np.concatenate((oof_pred_q[q_col].values, oof_pred_a[a_col].values), axis=1) * 0.6\n",
        "oof_pred_qa_sep.to_csv('drive/My Drive/GoogleQA/Data/train_oof_pred_roberta.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}